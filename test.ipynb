{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load a pre-trained BERT model and tokenizer\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize the input sentence\n",
    "sentence = \"This is an example sentence.\"\n",
    "tokenized_sentence = bert_tokenizer.tokenize(sentence)\n",
    "\n",
    "# Convert the tokenized sentence to BERT input format\n",
    "bert_input = bert_tokenizer.convert_tokens_to_ids(tokenized_sentence)\n",
    "\n",
    "# Convert bert_input to Pytorch Tensor\n",
    "bert_input = torch.tensor([bert_input])\n",
    "\n",
    "# Create attention mask\n",
    "attention_mask = torch.tensor([[1] * len(bert_input[0])])\n",
    "\n",
    "# Generate sentence embeddings\n",
    "bert_output = bert_model(bert_input, attention_mask=attention_mask)\n",
    "sentence_embeddings = bert_output[0][0]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def preprocess_fct(title,text):\n",
    "    from bs4 import BeautifulSoup\n",
    "    import nltk\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    #1: Delete html balises and lower text\n",
    "    title = BeautifulSoup(title).get_text().lower()\n",
    "    text = BeautifulSoup(text).get_text().lower()\n",
    "    #2: Deelete english words:\n",
    "    #tokenizer\n",
    "    tokenizer = nltk.RegexpTokenizer(r'[a-zA_\\-+#]*\\.?[a-zA_\\+#]+')\n",
    "    tokens_list_title = tokenizer.tokenize(title)\n",
    "    tokens_list_text = tokenizer.tokenize(text)\n",
    "    english_stop_words=nltk.corpus.stopwords.words('English')\n",
    "    clean_tokens_list_title = [word for word in tokens_list_title if word not in english_stop_words]\n",
    "    clean_tokens_list_text = [word for word in tokens_list_text if word not in english_stop_words]\n",
    "    #3: lemmatization:\n",
    "    trans = WordNetLemmatizer()\n",
    "    trans_title = [trans.lemmatize(word) for word in clean_tokens_list_title]\n",
    "    trans_text = [trans.lemmatize(word) for word in clean_tokens_list_text]\n",
    "    final_text = trans_title + trans_text\n",
    "\n",
    "    return \" \".join(final_text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def use_embedding(text):\n",
    "    #call the USE\n",
    "    text = text\n",
    "    print('Loading the USE tokenizer ...')\n",
    "    embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "    print('create the embedded matrix ...')\n",
    "    embedding = embed([text])\n",
    "    return pd.DataFrame(embedding.numpy())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def predict_emdedded_matrix(doc_df):\n",
    "    loaded_model = torch.load('use_model.pkl')\n",
    "    doc_pred = pd.DataFrame(loaded_model.predict(doc_df))\n",
    "    target_labels = pd.read_csv('/Users/maurelco/Developer/Python/Projet4/data/Cleaned/USE_labels_tags.csv', index=False)\n",
    "    doc_pred.columns = target_labels\n",
    "    tags = doc_pred[doc_pred == 1]\n",
    "    return np.array(tags.index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "def fonction_api(title, text):\n",
    "    print('1/ Preprocessing the title & Text ...')\n",
    "    #call the preprocessing fonction\n",
    "    text = preprocess_fct(title, text)\n",
    "    print(text)\n",
    "    print(type(text))\n",
    "    print('2/ Transforming the Text into an embedding matrix ... ')\n",
    "    #call the USE\n",
    "    doc_df = use_embedding(text)\n",
    "    print('3/ Load the MultiOutputClassifier and 126 target_labels to predict thet tags of the input text ...')\n",
    "    array = predict_emdedded_matrix(doc_df)\n",
    "    print('4/ print tags ...')\n",
    "    for tag in array:\n",
    "        print('tag')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "title = 'How to create a dataframe with python?'\n",
    "text = '<p> I have a big numpy array with 30 columns and 100 rows but am not sure how to use the pandas library in python to transform this array in a dataframe. Could you please help me here? <p>'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/ Preprocessing the title & Text ...\n",
      "create dataframe python big numpy array column row sure use panda library python transform array dataframe could please help\n",
      "<class 'str'>\n",
      "2/ Transforming the Text into an embedding matrix ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-29 20:26:32.539021: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-29 20:26:36.880304: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-29 20:26:38.498671: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-29 20:26:38.680 python[40295:1053232] -[MPSGraph coordinateAlongAxisTensor:withShapeTensor:name:]: unrecognized selector sent to instance 0x600014d21180\n"
     ]
    }
   ],
   "source": [
    "fonction_api(title=title, text=text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtext\u001B[49m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "loaded_model = torch.load('use_model.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MultiOutputClassifier' object has no attribute 'named_children'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mloaded_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnamed_children\u001B[49m()\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'MultiOutputClassifier' object has no attribute 'named_children'"
     ]
    }
   ],
   "source": [
    "loaded_model.predict()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "def preprocess_fct(title,text):\n",
    "    #1: Delete html balises and lower text\n",
    "    title = BeautifulSoup(title).get_text().lower()\n",
    "    text = BeautifulSoup(text).get_text().lower()\n",
    "    #2: Deelete english words:\n",
    "    #tokenizer\n",
    "    tokenizer = nltk.RegexpTokenizer(r'[a-zA_\\-+#]*\\.?[a-zA_\\+#]+')\n",
    "    tokens_list_title = tokenizer.tokenize(title)\n",
    "    tokens_list_text = tokenizer.tokenize(text)\n",
    "    english_stop_words=nltk.corpus.stopwords.words('English')\n",
    "    clean_tokens_list_title = [word for word in tokens_list_title if word not in english_stop_words]\n",
    "    clean_tokens_list_text = [word for word in tokens_list_text if word not in english_stop_words]\n",
    "    #3: lemmatization:\n",
    "    trans = WordNetLemmatizer()\n",
    "    trans_title = [trans.lemmatize(word) for word in clean_tokens_list_title]\n",
    "    trans_text = [trans.lemmatize(word) for word in clean_tokens_list_text]\n",
    "    final_text = trans_title + trans_text\n",
    "\n",
    "    return \" \".join(final_text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "def fonction_api(title, text):\n",
    "    #call the preprocessing fonction\n",
    "    text = preprocess_fct(title, text)\n",
    "    #call the USE\n",
    "    df = use_embedding(text)\n",
    "    loaded_model = torch.load('use_model.pkl')\n",
    "    # The USE model has been solved in df_USE_matrix_embedding\n",
    "    loaded_model.predict(df)\n",
    "    y_pred_test_use_df = pd.DataFrame(y_pred_test_use)\n",
    "    y_pred_test_use_df.columns = y_test_use.columns\n",
    "    doc[doc == 1]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def use_embedding(text):\n",
    "    #call the USE\n",
    "    embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "    embedding = embed(text)\n",
    "    return pd.DataFrame(embedding.numpy())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def predict_emdedded_matrix(df):\n",
    "    loaded_model = torch.load('use_model.pkl')\n",
    "    loaded_model.predict(df)\n",
    "    pred = pd.DataFrame(loaded_model.predict(df))\n",
    "    pred.columns = loaded_model.__class__\n",
    "    doc[doc == 1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bert_output[0][0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# fonction - input (text) output(embedding text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenized_sentence"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "attention_mask"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bert_input"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sentence_embeddings"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bert_output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#chaque tokens a un embedding qui le corresponding -"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "last_hidden_states = bert_output.last_hidden_state\n",
    "last_hidden_states"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "last_hidden_states = last_hidden_states.detach()\n",
    "features_bert = np.array(last_hidden_states).mean(axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features_bert"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                                               Title  \\\n0  giving unix process exclusive rw access directory   \n1                automatic repaint minimizing window   \n2  man-in-the-middle attack security threat ssh a...   \n3           managing data access simple winforms app   \n4                             render basic html view   \n\n                                                Body  \\\n0  way sandbox linux process certain directory gi...   \n1  jframe two panel one panel draw line working m...   \n2  expert network security pardon question smart ...   \n3  simple winforms data entry app us sqlite alway...   \n4  basic node.js app trying get ground using expr...   \n\n                                              Tags  \\\n0             linux ubuntu process sandbox selinux   \n1                java graphics jframe jpanel paint   \n2  security ssh ssh-keys openssh man-in-the-middle   \n3       c# winforms sqlite datatable sqlconnection   \n4          javascript html node.js mongodb express   \n\n                                         _clean_tags  _len_body  \\\n0  ['linux', 'ubuntu', 'process', 'sandbox', 'sel...        526   \n1  ['java', 'graphics', 'jframe', 'jpanel', 'paint']       2969   \n2  ['security', 'ssh', 'ssh-keys', 'openssh', 'ma...        447   \n3  ['c#', 'winforms', 'sqlite', 'datatable', 'sql...       2537   \n4  ['javascript', 'html', 'node.js', 'mongodb', '...        335   \n\n                                              Body_2  _len_body_2  \\\n0  sandbox linux process certain directory give p...          462   \n1  jframe two panel panel draw line working minim...         2855   \n2  expert network security pardon smart automatin...          414   \n3  simple winforms entry app u sqlite always sing...         2382   \n4  basic node.js app get ground express framework...          292   \n\n                                              Body_3  \\\n0  sandbox linux process certain directory proces...   \n1  jframe panel panel draw line minimized window ...   \n2  expert network security pardon smart automatin...   \n3  winforms entry app sqlite always single-user a...   \n4  basic node.js app get ground express framework...   \n\n                                             Title_2  \n0  giving unix process exclusive rw access directory  \n1                automatic repaint minimizing window  \n2  man-in-the-middle attack security threat ssh a...  \n3                  managing data access winforms app  \n4                             render basic html view  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Title</th>\n      <th>Body</th>\n      <th>Tags</th>\n      <th>_clean_tags</th>\n      <th>_len_body</th>\n      <th>Body_2</th>\n      <th>_len_body_2</th>\n      <th>Body_3</th>\n      <th>Title_2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>giving unix process exclusive rw access directory</td>\n      <td>way sandbox linux process certain directory gi...</td>\n      <td>linux ubuntu process sandbox selinux</td>\n      <td>['linux', 'ubuntu', 'process', 'sandbox', 'sel...</td>\n      <td>526</td>\n      <td>sandbox linux process certain directory give p...</td>\n      <td>462</td>\n      <td>sandbox linux process certain directory proces...</td>\n      <td>giving unix process exclusive rw access directory</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>automatic repaint minimizing window</td>\n      <td>jframe two panel one panel draw line working m...</td>\n      <td>java graphics jframe jpanel paint</td>\n      <td>['java', 'graphics', 'jframe', 'jpanel', 'paint']</td>\n      <td>2969</td>\n      <td>jframe two panel panel draw line working minim...</td>\n      <td>2855</td>\n      <td>jframe panel panel draw line minimized window ...</td>\n      <td>automatic repaint minimizing window</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>man-in-the-middle attack security threat ssh a...</td>\n      <td>expert network security pardon question smart ...</td>\n      <td>security ssh ssh-keys openssh man-in-the-middle</td>\n      <td>['security', 'ssh', 'ssh-keys', 'openssh', 'ma...</td>\n      <td>447</td>\n      <td>expert network security pardon smart automatin...</td>\n      <td>414</td>\n      <td>expert network security pardon smart automatin...</td>\n      <td>man-in-the-middle attack security threat ssh a...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>managing data access simple winforms app</td>\n      <td>simple winforms data entry app us sqlite alway...</td>\n      <td>c# winforms sqlite datatable sqlconnection</td>\n      <td>['c#', 'winforms', 'sqlite', 'datatable', 'sql...</td>\n      <td>2537</td>\n      <td>simple winforms entry app u sqlite always sing...</td>\n      <td>2382</td>\n      <td>winforms entry app sqlite always single-user a...</td>\n      <td>managing data access winforms app</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>render basic html view</td>\n      <td>basic node.js app trying get ground using expr...</td>\n      <td>javascript html node.js mongodb express</td>\n      <td>['javascript', 'html', 'node.js', 'mongodb', '...</td>\n      <td>335</td>\n      <td>basic node.js app get ground express framework...</td>\n      <td>292</td>\n      <td>basic node.js app get ground express framework...</td>\n      <td>render basic html view</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/Users/maurelco/Developer/Python/Projet4/data/Cleaned/df_process_text_3.csv')\n",
    "df.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                                               Title  \\\n0  giving unix process exclusive rw access directory   \n1                automatic repaint minimizing window   \n2  man-in-the-middle attack security threat ssh a...   \n3           managing data access simple winforms app   \n4                             render basic html view   \n\n                                                Body  \\\n0  way sandbox linux process certain directory gi...   \n1  jframe two panel one panel draw line working m...   \n2  expert network security pardon question smart ...   \n3  simple winforms data entry app us sqlite alway...   \n4  basic node.js app trying get ground using expr...   \n\n                                              Tags  \\\n0             linux ubuntu process sandbox selinux   \n1                java graphics jframe jpanel paint   \n2  security ssh ssh-keys openssh man-in-the-middle   \n3       c# winforms sqlite datatable sqlconnection   \n4          javascript html node.js mongodb express   \n\n                                         _clean_tags  _len_body  \\\n0  ['linux', 'ubuntu', 'process', 'sandbox', 'sel...        526   \n1  ['java', 'graphics', 'jframe', 'jpanel', 'paint']       2969   \n2  ['security', 'ssh', 'ssh-keys', 'openssh', 'ma...        447   \n3  ['c#', 'winforms', 'sqlite', 'datatable', 'sql...       2537   \n4  ['javascript', 'html', 'node.js', 'mongodb', '...        335   \n\n                                              Body_2  _len_body_2  \\\n0  sandbox linux process certain directory give p...          462   \n1  jframe two panel panel draw line working minim...         2855   \n2  expert network security pardon smart automatin...          414   \n3  simple winforms entry app u sqlite always sing...         2382   \n4  basic node.js app get ground express framework...          292   \n\n                                              Body_3  \\\n0  sandbox linux process certain directory proces...   \n1  jframe panel panel draw line minimized window ...   \n2  expert network security pardon smart automatin...   \n3  winforms entry app sqlite always single-user a...   \n4  basic node.js app get ground express framework...   \n\n                                             Title_2  \\\n0  giving unix process exclusive rw access directory   \n1                automatic repaint minimizing window   \n2  man-in-the-middle attack security threat ssh a...   \n3                  managing data access winforms app   \n4                             render basic html view   \n\n                                                Text  \n0  giving unix process exclusive rw access direct...  \n1  automatic repaint minimizing window jframe two...  \n2  man-in-the-middle attack security threat ssh a...  \n3  managing data access simple winforms app simpl...  \n4  render basic html view basic node.js app tryin...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Title</th>\n      <th>Body</th>\n      <th>Tags</th>\n      <th>_clean_tags</th>\n      <th>_len_body</th>\n      <th>Body_2</th>\n      <th>_len_body_2</th>\n      <th>Body_3</th>\n      <th>Title_2</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>giving unix process exclusive rw access directory</td>\n      <td>way sandbox linux process certain directory gi...</td>\n      <td>linux ubuntu process sandbox selinux</td>\n      <td>['linux', 'ubuntu', 'process', 'sandbox', 'sel...</td>\n      <td>526</td>\n      <td>sandbox linux process certain directory give p...</td>\n      <td>462</td>\n      <td>sandbox linux process certain directory proces...</td>\n      <td>giving unix process exclusive rw access directory</td>\n      <td>giving unix process exclusive rw access direct...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>automatic repaint minimizing window</td>\n      <td>jframe two panel one panel draw line working m...</td>\n      <td>java graphics jframe jpanel paint</td>\n      <td>['java', 'graphics', 'jframe', 'jpanel', 'paint']</td>\n      <td>2969</td>\n      <td>jframe two panel panel draw line working minim...</td>\n      <td>2855</td>\n      <td>jframe panel panel draw line minimized window ...</td>\n      <td>automatic repaint minimizing window</td>\n      <td>automatic repaint minimizing window jframe two...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>man-in-the-middle attack security threat ssh a...</td>\n      <td>expert network security pardon question smart ...</td>\n      <td>security ssh ssh-keys openssh man-in-the-middle</td>\n      <td>['security', 'ssh', 'ssh-keys', 'openssh', 'ma...</td>\n      <td>447</td>\n      <td>expert network security pardon smart automatin...</td>\n      <td>414</td>\n      <td>expert network security pardon smart automatin...</td>\n      <td>man-in-the-middle attack security threat ssh a...</td>\n      <td>man-in-the-middle attack security threat ssh a...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>managing data access simple winforms app</td>\n      <td>simple winforms data entry app us sqlite alway...</td>\n      <td>c# winforms sqlite datatable sqlconnection</td>\n      <td>['c#', 'winforms', 'sqlite', 'datatable', 'sql...</td>\n      <td>2537</td>\n      <td>simple winforms entry app u sqlite always sing...</td>\n      <td>2382</td>\n      <td>winforms entry app sqlite always single-user a...</td>\n      <td>managing data access winforms app</td>\n      <td>managing data access simple winforms app simpl...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>render basic html view</td>\n      <td>basic node.js app trying get ground using expr...</td>\n      <td>javascript html node.js mongodb express</td>\n      <td>['javascript', 'html', 'node.js', 'mongodb', '...</td>\n      <td>335</td>\n      <td>basic node.js app get ground express framework...</td>\n      <td>292</td>\n      <td>basic node.js app get ground express framework...</td>\n      <td>render basic html view</td>\n      <td>render basic html view basic node.js app tryin...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text'] = df['Title'] + ' ' + df['Body']\n",
    "df.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "Title          0\nBody           0\nTags           0\n_clean_tags    0\n_len_body      0\nBody_2         0\n_len_body_2    0\nBody_3         0\nTitle_2        0\nText           0\ndtype: int64"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "(40300, 10)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reduced = df.drop(df[df['_len_body'] > 1500].index)\n",
    "df_reduced.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "df_reduced = df_reduced.sample(frac=0.6)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "(24180, 10)"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reduced.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   Title  \\\n4904         aws elastic beanstalk unable access aws msk   \n24519                            soap message expiration   \n47813  python panda equivalent sql case statement usi...   \n35144  java stack overflow error increase stack size ...   \n20888               creating bitmask large number option   \n...                                                  ...   \n15847  easiest way handle window close event winapi c...   \n45172    transition button using .delay jquery bootstrap   \n2814   c-family semantic autocompletion plugins vim c...   \n25043                       build boost-libraries iphone   \n29788              get file local folder web application   \n\n                                                    Body  \\\n4904   aws msk cluster running inside vpc subnets cre...   \n24519  use time-stamp soap header implement message e...   \n47813  new python trying see elegant solution time se...   \n35144  running program written java eclipse program d...   \n20888  android app class containing data exposed gett...   \n...                                                  ...   \n15847  writing console multi-process application c++ ...   \n45172  testing something simple created basic login f...   \n2814   using -bit vim window version haroogan +python...   \n25043  someone tell find detailed guide build boost-l...   \n29788  gridview aspx page need show xml file folder c...   \n\n                                                    Tags  \\\n4904   amazon-web-services apache-kafka aws-lambda am...   \n24519                  c# .net asp.net web-services soap   \n47813  python sql pandas window-functions case-statement   \n35144      java eclipse jvm stack-overflow jvm-arguments   \n20888  java android serialization bit-manipulation bi...   \n...                                                  ...   \n15847         c++ windows winapi process synchronization   \n45172  jquery css twitter-bootstrap webforms css-tran...   \n2814      vim autocomplete clang clang-complete libclang   \n25043                       ios iphone xcode boost build   \n29788                    javascript c# asp.net ajax html   \n\n                                             _clean_tags  _len_body  \\\n4904   ['amazon-web-services', 'apache-kafka', 'aws-l...        786   \n24519  ['c#', '.net', 'asp.net', 'web-services', 'soap']         88   \n47813  ['python', 'sql', 'pandas', 'window-functions'...       1170   \n35144  ['java', 'eclipse', 'jvm', 'stack-overflow', '...        592   \n20888  ['java', 'android', 'serialization', 'bit-mani...        845   \n...                                                  ...        ...   \n15847  ['c++', 'windows', 'winapi', 'process', 'synch...        481   \n45172  ['jquery', 'css', 'twitter-bootstrap', 'webfor...       1154   \n2814   ['vim', 'autocomplete', 'clang', 'clang-comple...        500   \n25043       ['ios', 'iphone', 'xcode', 'boost', 'build']        227   \n29788    ['javascript', 'c#', 'asp.net', 'ajax', 'html']        796   \n\n                                                  Body_2  _len_body_2  \\\n4904   aws msk cluster running inside vpc subnets cre...          765   \n24519  time-stamp soap header implement message expir...           78   \n47813  python elegant solution time series telematics...         1044   \n35144  running program written java eclipse program d...          529   \n20888  android app class containing exposed getters c...          725   \n...                                                  ...          ...   \n15847  writing console multi-process c++ winapi dispa...          436   \n45172  testing something simple created basic login b...         1053   \n2814   -bit vim window version haroogan +python +pyth...          463   \n25043  someone tell find detailed guide build boost-l...          206   \n29788  gridview aspx show xml file folder client mach...          723   \n\n                                                  Body_3  \\\n4904   aws msk cluster vpc subnets elastic beanstalk ...   \n24519  time-stamp soap header message expiration .net...   \n47813  python elegant solution time series telematics...   \n35144  written java eclipse deep level recursion larg...   \n20888  android app class containing exposed getters c...   \n...                                                  ...   \n15847  writing console multi-process c++ winapi dispa...   \n45172  testing basic login bootstrap follows class fo...   \n2814   -bit vim window version haroogan +python +pyth...   \n25043  someone tell find detailed guide build boost-l...   \n29788  gridview aspx show xml file client machine any...   \n\n                                                 Title_2  \\\n4904         aws elastic beanstalk unable access aws msk   \n24519                            soap message expiration   \n47813  python panda equivalent sql case statement usi...   \n35144  java stack overflow error increase stack size ...   \n20888                      creating bitmask large option   \n...                                                  ...   \n15847  easiest way handle window close winapi console...   \n45172    transition button using .delay jquery bootstrap   \n2814   c-family semantic autocompletion plugins vim c...   \n25043                       build boost-libraries iphone   \n29788                     get file local web application   \n\n                                                    Text  \n4904   aws elastic beanstalk unable access aws msk aw...  \n24519  soap message expiration use time-stamp soap he...  \n47813  python panda equivalent sql case statement usi...  \n35144  java stack overflow error increase stack size ...  \n20888  creating bitmask large number option android a...  \n...                                                  ...  \n15847  easiest way handle window close event winapi c...  \n45172  transition button using .delay jquery bootstra...  \n2814   c-family semantic autocompletion plugins vim c...  \n25043  build boost-libraries iphone someone tell find...  \n29788  get file local folder web application gridview...  \n\n[24180 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Title</th>\n      <th>Body</th>\n      <th>Tags</th>\n      <th>_clean_tags</th>\n      <th>_len_body</th>\n      <th>Body_2</th>\n      <th>_len_body_2</th>\n      <th>Body_3</th>\n      <th>Title_2</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4904</th>\n      <td>aws elastic beanstalk unable access aws msk</td>\n      <td>aws msk cluster running inside vpc subnets cre...</td>\n      <td>amazon-web-services apache-kafka aws-lambda am...</td>\n      <td>['amazon-web-services', 'apache-kafka', 'aws-l...</td>\n      <td>786</td>\n      <td>aws msk cluster running inside vpc subnets cre...</td>\n      <td>765</td>\n      <td>aws msk cluster vpc subnets elastic beanstalk ...</td>\n      <td>aws elastic beanstalk unable access aws msk</td>\n      <td>aws elastic beanstalk unable access aws msk aw...</td>\n    </tr>\n    <tr>\n      <th>24519</th>\n      <td>soap message expiration</td>\n      <td>use time-stamp soap header implement message e...</td>\n      <td>c# .net asp.net web-services soap</td>\n      <td>['c#', '.net', 'asp.net', 'web-services', 'soap']</td>\n      <td>88</td>\n      <td>time-stamp soap header implement message expir...</td>\n      <td>78</td>\n      <td>time-stamp soap header message expiration .net...</td>\n      <td>soap message expiration</td>\n      <td>soap message expiration use time-stamp soap he...</td>\n    </tr>\n    <tr>\n      <th>47813</th>\n      <td>python panda equivalent sql case statement usi...</td>\n      <td>new python trying see elegant solution time se...</td>\n      <td>python sql pandas window-functions case-statement</td>\n      <td>['python', 'sql', 'pandas', 'window-functions'...</td>\n      <td>1170</td>\n      <td>python elegant solution time series telematics...</td>\n      <td>1044</td>\n      <td>python elegant solution time series telematics...</td>\n      <td>python panda equivalent sql case statement usi...</td>\n      <td>python panda equivalent sql case statement usi...</td>\n    </tr>\n    <tr>\n      <th>35144</th>\n      <td>java stack overflow error increase stack size ...</td>\n      <td>running program written java eclipse program d...</td>\n      <td>java eclipse jvm stack-overflow jvm-arguments</td>\n      <td>['java', 'eclipse', 'jvm', 'stack-overflow', '...</td>\n      <td>592</td>\n      <td>running program written java eclipse program d...</td>\n      <td>529</td>\n      <td>written java eclipse deep level recursion larg...</td>\n      <td>java stack overflow error increase stack size ...</td>\n      <td>java stack overflow error increase stack size ...</td>\n    </tr>\n    <tr>\n      <th>20888</th>\n      <td>creating bitmask large number option</td>\n      <td>android app class containing data exposed gett...</td>\n      <td>java android serialization bit-manipulation bi...</td>\n      <td>['java', 'android', 'serialization', 'bit-mani...</td>\n      <td>845</td>\n      <td>android app class containing exposed getters c...</td>\n      <td>725</td>\n      <td>android app class containing exposed getters c...</td>\n      <td>creating bitmask large option</td>\n      <td>creating bitmask large number option android a...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>15847</th>\n      <td>easiest way handle window close event winapi c...</td>\n      <td>writing console multi-process application c++ ...</td>\n      <td>c++ windows winapi process synchronization</td>\n      <td>['c++', 'windows', 'winapi', 'process', 'synch...</td>\n      <td>481</td>\n      <td>writing console multi-process c++ winapi dispa...</td>\n      <td>436</td>\n      <td>writing console multi-process c++ winapi dispa...</td>\n      <td>easiest way handle window close winapi console...</td>\n      <td>easiest way handle window close event winapi c...</td>\n    </tr>\n    <tr>\n      <th>45172</th>\n      <td>transition button using .delay jquery bootstrap</td>\n      <td>testing something simple created basic login f...</td>\n      <td>jquery css twitter-bootstrap webforms css-tran...</td>\n      <td>['jquery', 'css', 'twitter-bootstrap', 'webfor...</td>\n      <td>1154</td>\n      <td>testing something simple created basic login b...</td>\n      <td>1053</td>\n      <td>testing basic login bootstrap follows class fo...</td>\n      <td>transition button using .delay jquery bootstrap</td>\n      <td>transition button using .delay jquery bootstra...</td>\n    </tr>\n    <tr>\n      <th>2814</th>\n      <td>c-family semantic autocompletion plugins vim c...</td>\n      <td>using -bit vim window version haroogan +python...</td>\n      <td>vim autocomplete clang clang-complete libclang</td>\n      <td>['vim', 'autocomplete', 'clang', 'clang-comple...</td>\n      <td>500</td>\n      <td>-bit vim window version haroogan +python +pyth...</td>\n      <td>463</td>\n      <td>-bit vim window version haroogan +python +pyth...</td>\n      <td>c-family semantic autocompletion plugins vim c...</td>\n      <td>c-family semantic autocompletion plugins vim c...</td>\n    </tr>\n    <tr>\n      <th>25043</th>\n      <td>build boost-libraries iphone</td>\n      <td>someone tell find detailed guide build boost-l...</td>\n      <td>ios iphone xcode boost build</td>\n      <td>['ios', 'iphone', 'xcode', 'boost', 'build']</td>\n      <td>227</td>\n      <td>someone tell find detailed guide build boost-l...</td>\n      <td>206</td>\n      <td>someone tell find detailed guide build boost-l...</td>\n      <td>build boost-libraries iphone</td>\n      <td>build boost-libraries iphone someone tell find...</td>\n    </tr>\n    <tr>\n      <th>29788</th>\n      <td>get file local folder web application</td>\n      <td>gridview aspx page need show xml file folder c...</td>\n      <td>javascript c# asp.net ajax html</td>\n      <td>['javascript', 'c#', 'asp.net', 'ajax', 'html']</td>\n      <td>796</td>\n      <td>gridview aspx show xml file folder client mach...</td>\n      <td>723</td>\n      <td>gridview aspx show xml file client machine any...</td>\n      <td>get file local web application</td>\n      <td>get file local folder web application gridview...</td>\n    </tr>\n  </tbody>\n</table>\n<p>24180 rows Ã— 10 columns</p>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reduced"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "[4904,\n 24519,\n 47813,\n 35144,\n 20888,\n 18260,\n 48459,\n 36272,\n 40821,\n 26569,\n 27675,\n 43961,\n 41664,\n 18666,\n 22291,\n 29344,\n 44582,\n 6670,\n 7281,\n 41218]"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_index = []\n",
    "for i, row in df_reduced.iterrows():\n",
    "    list_index.append(i)\n",
    "\n",
    "list_index[:20]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "#Faire un essai sans traitement (lemmatization, stop words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "sentences = df_reduced.Text.to_list()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "112"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "import nltk\n",
    "tokenizer = nltk.RegexpTokenizer(r'[a-zA_\\-+#]*\\.?[a-zA_\\+#]+')\n",
    "sentence_tokens= tokenizer.tokenize(sentences[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "['soap',\n 'message',\n 'expiration',\n 'use',\n 'time-stamp',\n 'soap',\n 'header',\n 'implement',\n 'message',\n 'expiration',\n 'note',\n 'using',\n '.net',\n 'asmx',\n 'service',\n 'wcf']"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_tokens"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "16"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_tokens)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.BERT"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "df_reduced['bert_features']= df_reduced['Text'].apply(lambda x : np.array((bert_model(**(bert_tokenizer.encode_plus(x, None,\n",
    "                                                                               truncation=True,\n",
    "                                                                               add_special_tokens=True,\n",
    "                                                                               max_length=512,\n",
    "                                                                               padding='max_length',\n",
    "                                                                               return_token_type_ids=True,\n",
    "                                                                               return_tensors='pt')))).last_hidden_state.detach()).mean(axis=1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   Title  \\\n4904         aws elastic beanstalk unable access aws msk   \n24519                            soap message expiration   \n47813  python panda equivalent sql case statement usi...   \n35144  java stack overflow error increase stack size ...   \n20888               creating bitmask large number option   \n18260       cannot post span value document.form .submit   \n48459                    cors policy issue heroku server   \n36272  issue maven jetty debug eclipse breakpoints ge...   \n40821      jquery form serialize multi dimensional array   \n26569  react conditional rendering cs class animate s...   \n\n                                                    Body  \\\n4904   aws msk cluster running inside vpc subnets cre...   \n24519  use time-stamp soap header implement message e...   \n47813  new python trying see elegant solution time se...   \n35144  running program written java eclipse program d...   \n20888  android app class containing data exposed gett...   \n18260  writing form use document.form .submit post va...   \n48459  made client-server application backend us node...   \n36272  trying debug maven project jetty server eclips...   \n40821  need get value form format json post via ajax ...   \n26569  using animate scroll library react-bootstrap p...   \n\n                                                    Tags  \\\n4904   amazon-web-services apache-kafka aws-lambda am...   \n24519                  c# .net asp.net web-services soap   \n47813  python sql pandas window-functions case-statement   \n35144      java eclipse jvm stack-overflow jvm-arguments   \n20888  java android serialization bit-manipulation bi...   \n18260                javascript jquery forms http submit   \n48459        javascript node.js reactjs heroku preflight   \n36272                    java eclipse spring maven jetty   \n40821                javascript jquery arrays json forms   \n26569    css reactjs class ternary conditional-rendering   \n\n                                             _clean_tags  _len_body  \\\n4904   ['amazon-web-services', 'apache-kafka', 'aws-l...        786   \n24519  ['c#', '.net', 'asp.net', 'web-services', 'soap']         88   \n47813  ['python', 'sql', 'pandas', 'window-functions'...       1170   \n35144  ['java', 'eclipse', 'jvm', 'stack-overflow', '...        592   \n20888  ['java', 'android', 'serialization', 'bit-mani...        845   \n18260  ['javascript', 'jquery', 'forms', 'http', 'sub...        415   \n48459  ['javascript', 'node.js', 'reactjs', 'heroku',...        446   \n36272    ['java', 'eclipse', 'spring', 'maven', 'jetty']        724   \n40821  ['javascript', 'jquery', 'arrays', 'json', 'fo...        679   \n26569  ['css', 'reactjs', 'class', 'ternary', 'condit...        727   \n\n                                                  Body_2  _len_body_2  \\\n4904   aws msk cluster running inside vpc subnets cre...          765   \n24519  time-stamp soap header implement message expir...           78   \n47813  python elegant solution time series telematics...         1044   \n35144  running program written java eclipse program d...          529   \n20888  android app class containing exposed getters c...          725   \n18260  writing document.form .submit post hope x http...          324   \n48459  made client-server backend u node express mong...          378   \n36272  debug maven project jetty server eclipse sprin...          648   \n40821  get format json post via ajax format achieve i...          471   \n26569  animate scroll library react-bootstrap project...          670   \n\n                                                  Body_3  \\\n4904   aws msk cluster vpc subnets elastic beanstalk ...   \n24519  time-stamp soap header message expiration .net...   \n47813  python elegant solution time series telematics...   \n35144  written java eclipse deep level recursion larg...   \n20888  android app class containing exposed getters c...   \n18260  writing document.form .submit post hope http.f...   \n48459  made client-server backend node express mongod...   \n36272  maven project jetty server eclipse spring tool...   \n40821  get format json post ajax format achieve id bo...   \n26569  animate scroll library react-bootstrap project...   \n\n                                                 Title_2  \\\n4904         aws elastic beanstalk unable access aws msk   \n24519                            soap message expiration   \n47813  python panda equivalent sql case statement usi...   \n35144  java stack overflow error increase stack size ...   \n20888                      creating bitmask large option   \n18260                   post value document.form .submit   \n48459                          cors policy heroku server   \n36272            maven jetty eclipse breakpoints skipped   \n40821      jquery form serialize multi dimensional array   \n26569  react conditional rendering c class animate sc...   \n\n                                                    Text  \\\n4904   aws elastic beanstalk unable access aws msk aw...   \n24519  soap message expiration use time-stamp soap he...   \n47813  python panda equivalent sql case statement usi...   \n35144  java stack overflow error increase stack size ...   \n20888  creating bitmask large number option android a...   \n18260  cannot post span value document.form .submit w...   \n48459  cors policy issue heroku server made client-se...   \n36272  issue maven jetty debug eclipse breakpoints ge...   \n40821  jquery form serialize multi dimensional array ...   \n26569  react conditional rendering cs class animate s...   \n\n                                           bert_features  \n4904   [[-0.21572688, 0.043502435, 0.17954159, 0.0588...  \n24519  [[0.12147706, -0.4004427, 0.1871699, -0.053614...  \n47813  [[-0.23494641, -0.06181486, 0.78896916, -0.110...  \n35144  [[-0.034630988, -0.06871903, 0.26422969, -0.06...  \n20888  [[0.0013576947, -0.20459248, 0.26405495, 0.082...  \n18260  [[0.12432741, -0.14306657, 0.51982045, -0.0027...  \n48459  [[-0.17805444, -0.32579988, 0.5416442, 0.25021...  \n36272  [[-0.105132885, -0.16010264, 0.34793168, 0.112...  \n40821  [[0.029572075, -0.035203893, 0.390891, -0.0481...  \n26569  [[-0.1148364, 0.030055039, 0.58414066, 0.00338...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Title</th>\n      <th>Body</th>\n      <th>Tags</th>\n      <th>_clean_tags</th>\n      <th>_len_body</th>\n      <th>Body_2</th>\n      <th>_len_body_2</th>\n      <th>Body_3</th>\n      <th>Title_2</th>\n      <th>Text</th>\n      <th>bert_features</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4904</th>\n      <td>aws elastic beanstalk unable access aws msk</td>\n      <td>aws msk cluster running inside vpc subnets cre...</td>\n      <td>amazon-web-services apache-kafka aws-lambda am...</td>\n      <td>['amazon-web-services', 'apache-kafka', 'aws-l...</td>\n      <td>786</td>\n      <td>aws msk cluster running inside vpc subnets cre...</td>\n      <td>765</td>\n      <td>aws msk cluster vpc subnets elastic beanstalk ...</td>\n      <td>aws elastic beanstalk unable access aws msk</td>\n      <td>aws elastic beanstalk unable access aws msk aw...</td>\n      <td>[[-0.21572688, 0.043502435, 0.17954159, 0.0588...</td>\n    </tr>\n    <tr>\n      <th>24519</th>\n      <td>soap message expiration</td>\n      <td>use time-stamp soap header implement message e...</td>\n      <td>c# .net asp.net web-services soap</td>\n      <td>['c#', '.net', 'asp.net', 'web-services', 'soap']</td>\n      <td>88</td>\n      <td>time-stamp soap header implement message expir...</td>\n      <td>78</td>\n      <td>time-stamp soap header message expiration .net...</td>\n      <td>soap message expiration</td>\n      <td>soap message expiration use time-stamp soap he...</td>\n      <td>[[0.12147706, -0.4004427, 0.1871699, -0.053614...</td>\n    </tr>\n    <tr>\n      <th>47813</th>\n      <td>python panda equivalent sql case statement usi...</td>\n      <td>new python trying see elegant solution time se...</td>\n      <td>python sql pandas window-functions case-statement</td>\n      <td>['python', 'sql', 'pandas', 'window-functions'...</td>\n      <td>1170</td>\n      <td>python elegant solution time series telematics...</td>\n      <td>1044</td>\n      <td>python elegant solution time series telematics...</td>\n      <td>python panda equivalent sql case statement usi...</td>\n      <td>python panda equivalent sql case statement usi...</td>\n      <td>[[-0.23494641, -0.06181486, 0.78896916, -0.110...</td>\n    </tr>\n    <tr>\n      <th>35144</th>\n      <td>java stack overflow error increase stack size ...</td>\n      <td>running program written java eclipse program d...</td>\n      <td>java eclipse jvm stack-overflow jvm-arguments</td>\n      <td>['java', 'eclipse', 'jvm', 'stack-overflow', '...</td>\n      <td>592</td>\n      <td>running program written java eclipse program d...</td>\n      <td>529</td>\n      <td>written java eclipse deep level recursion larg...</td>\n      <td>java stack overflow error increase stack size ...</td>\n      <td>java stack overflow error increase stack size ...</td>\n      <td>[[-0.034630988, -0.06871903, 0.26422969, -0.06...</td>\n    </tr>\n    <tr>\n      <th>20888</th>\n      <td>creating bitmask large number option</td>\n      <td>android app class containing data exposed gett...</td>\n      <td>java android serialization bit-manipulation bi...</td>\n      <td>['java', 'android', 'serialization', 'bit-mani...</td>\n      <td>845</td>\n      <td>android app class containing exposed getters c...</td>\n      <td>725</td>\n      <td>android app class containing exposed getters c...</td>\n      <td>creating bitmask large option</td>\n      <td>creating bitmask large number option android a...</td>\n      <td>[[0.0013576947, -0.20459248, 0.26405495, 0.082...</td>\n    </tr>\n    <tr>\n      <th>18260</th>\n      <td>cannot post span value document.form .submit</td>\n      <td>writing form use document.form .submit post va...</td>\n      <td>javascript jquery forms http submit</td>\n      <td>['javascript', 'jquery', 'forms', 'http', 'sub...</td>\n      <td>415</td>\n      <td>writing document.form .submit post hope x http...</td>\n      <td>324</td>\n      <td>writing document.form .submit post hope http.f...</td>\n      <td>post value document.form .submit</td>\n      <td>cannot post span value document.form .submit w...</td>\n      <td>[[0.12432741, -0.14306657, 0.51982045, -0.0027...</td>\n    </tr>\n    <tr>\n      <th>48459</th>\n      <td>cors policy issue heroku server</td>\n      <td>made client-server application backend us node...</td>\n      <td>javascript node.js reactjs heroku preflight</td>\n      <td>['javascript', 'node.js', 'reactjs', 'heroku',...</td>\n      <td>446</td>\n      <td>made client-server backend u node express mong...</td>\n      <td>378</td>\n      <td>made client-server backend node express mongod...</td>\n      <td>cors policy heroku server</td>\n      <td>cors policy issue heroku server made client-se...</td>\n      <td>[[-0.17805444, -0.32579988, 0.5416442, 0.25021...</td>\n    </tr>\n    <tr>\n      <th>36272</th>\n      <td>issue maven jetty debug eclipse breakpoints ge...</td>\n      <td>trying debug maven project jetty server eclips...</td>\n      <td>java eclipse spring maven jetty</td>\n      <td>['java', 'eclipse', 'spring', 'maven', 'jetty']</td>\n      <td>724</td>\n      <td>debug maven project jetty server eclipse sprin...</td>\n      <td>648</td>\n      <td>maven project jetty server eclipse spring tool...</td>\n      <td>maven jetty eclipse breakpoints skipped</td>\n      <td>issue maven jetty debug eclipse breakpoints ge...</td>\n      <td>[[-0.105132885, -0.16010264, 0.34793168, 0.112...</td>\n    </tr>\n    <tr>\n      <th>40821</th>\n      <td>jquery form serialize multi dimensional array</td>\n      <td>need get value form format json post via ajax ...</td>\n      <td>javascript jquery arrays json forms</td>\n      <td>['javascript', 'jquery', 'arrays', 'json', 'fo...</td>\n      <td>679</td>\n      <td>get format json post via ajax format achieve i...</td>\n      <td>471</td>\n      <td>get format json post ajax format achieve id bo...</td>\n      <td>jquery form serialize multi dimensional array</td>\n      <td>jquery form serialize multi dimensional array ...</td>\n      <td>[[0.029572075, -0.035203893, 0.390891, -0.0481...</td>\n    </tr>\n    <tr>\n      <th>26569</th>\n      <td>react conditional rendering cs class animate s...</td>\n      <td>using animate scroll library react-bootstrap p...</td>\n      <td>css reactjs class ternary conditional-rendering</td>\n      <td>['css', 'reactjs', 'class', 'ternary', 'condit...</td>\n      <td>727</td>\n      <td>animate scroll library react-bootstrap project...</td>\n      <td>670</td>\n      <td>animate scroll library react-bootstrap project...</td>\n      <td>react conditional rendering c class animate sc...</td>\n      <td>react conditional rendering cs class animate s...</td>\n      <td>[[-0.1148364, 0.030055039, 0.58414066, 0.00338...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reduced.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "df_reduced.to_csv('/Users/maurelco/Developer/Python/Projet4/data/Cleaned/df_bert_2.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-2.15726882e-01,  4.35024351e-02,  1.79541588e-01,\n         5.88578321e-02,  2.75980122e-02, -9.06478986e-02,\n         7.83901215e-02,  1.14182360e-01, -1.61608770e-01,\n        -2.17892170e-01, -7.96109885e-02, -9.04970691e-02,\n        -2.07728848e-01,  7.24459141e-02,  1.93124693e-02,\n         4.54013348e-02, -2.22305208e-02, -6.17815405e-02,\n         5.99151105e-02,  2.33866200e-01,  1.35534540e-01,\n        -4.90814410e-02,  5.14919753e-04, -1.46716118e-01,\n         2.35698834e-01, -3.48612629e-02, -7.91258439e-02,\n        -2.15497732e-01, -9.19433460e-02, -7.49322027e-02,\n         8.87267068e-02,  4.27098721e-02,  1.10413581e-01,\n        -1.11858808e-01, -1.30094826e-01, -9.99551490e-02,\n         9.71758887e-02,  8.57443735e-02,  9.01920572e-02,\n         5.15249260e-02, -1.48496166e-01, -4.09181535e-01,\n         2.21606895e-01,  8.17013532e-02, -1.89081691e-02,\n        -3.44681591e-02,  1.29634514e-02, -8.40760469e-02,\n        -2.03936502e-01, -2.35718369e-01, -3.25723410e-01,\n         7.41296113e-02,  5.13417348e-02,  9.16319117e-02,\n         9.67666656e-02,  4.56142165e-02,  2.24605426e-01,\n        -3.47855121e-01, -4.86301910e-03, -2.08374381e-01,\n         1.16937704e-01, -1.03412844e-01,  1.53795451e-01,\n         2.18458131e-01, -9.64864809e-03,  2.41644368e-01,\n        -1.35467574e-02,  2.08031222e-01, -3.10347080e-01,\n         5.83592243e-02, -1.00500785e-01,  1.66587919e-01,\n        -4.50031608e-02,  1.77098110e-01,  3.22253513e-03,\n        -1.35814808e-02, -8.77542943e-02,  1.52034402e-01,\n         2.31850535e-01,  4.53353822e-02, -8.25433210e-02,\n         3.62219244e-01, -9.58720669e-02, -1.17565289e-01,\n         1.57565013e-01, -1.70323942e-02,  8.38811770e-02,\n         4.50524203e-02, -2.54661590e-01,  2.78882086e-01,\n         3.52037847e-01, -5.67104928e-02,  1.02343649e-01,\n         2.60942988e-02,  6.30660057e-02, -3.23934332e-02,\n        -1.72054440e-01,  1.29686996e-01,  9.98716950e-02,\n         1.32901892e-01, -2.12971509e-01,  3.78089026e-02,\n        -2.10520327e-01, -7.01646805e-02, -2.30056465e-01,\n        -3.07416506e-02, -3.41371037e-02,  1.68498337e-01,\n        -5.09865955e-02,  2.70359755e-01,  1.13465590e-03,\n         1.69033274e-01, -9.25413445e-02, -1.53223472e-02,\n        -2.45376065e-01, -3.60244177e-02, -7.06343278e-02,\n        -1.06501788e-01,  3.29299003e-01,  3.08211744e-02,\n        -9.25453231e-02,  3.13411593e-01, -5.15409298e-02,\n         5.46832979e-01,  5.07177301e-02, -1.16081620e-02,\n        -1.97348714e-01,  5.81245050e-02,  2.40785494e-01,\n         1.91722438e-03,  9.32826027e-02,  5.34477904e-02,\n         1.38675928e-01, -3.27620097e-02, -8.22231360e-03,\n         2.98878551e-02,  7.30329240e-03,  2.12514386e-01,\n         5.40887006e-02, -1.77187026e-01,  1.90317221e-02,\n        -1.25127167e-01,  1.14621013e-01,  4.22130637e-02,\n         2.86027435e-02,  1.22490056e-01, -1.03074849e-01,\n         6.72538877e-02,  8.99138674e-02,  3.19522530e-01,\n        -2.14568209e-02,  1.35891393e-01,  8.82480070e-02,\n         8.80792812e-02, -1.71353638e-01,  6.09987527e-02,\n         1.05502754e-02, -2.74526589e-02, -7.16112852e-02,\n         5.03839403e-02,  2.64182538e-01,  2.36887380e-01,\n        -2.54492015e-01,  1.04224212e-01,  3.67662400e-01,\n        -2.16055185e-01, -3.26550752e-02, -1.05630765e-02,\n        -2.03399956e-02, -8.07089284e-02, -1.54575214e-01,\n        -1.93112984e-01,  2.66624004e-01, -6.43508211e-02,\n        -2.38955140e-01,  5.39611131e-02,  2.26357609e-01,\n        -2.19844341e-01,  7.51046166e-02,  1.12567633e-01,\n        -1.69741184e-01,  1.10321529e-01,  6.51253993e-03,\n        -1.48169231e-02, -4.63009439e-02,  8.80952105e-02,\n         1.47473902e-01, -5.02661988e-02,  9.74541530e-02,\n         8.89932141e-02, -3.31118554e-01, -2.14219496e-01,\n         1.27256691e-01,  1.05292745e-01,  3.52451116e-01,\n        -1.70104399e-01, -8.46401155e-02,  3.41811866e-01,\n         3.50946561e-02, -3.65502536e-02,  6.07789934e-01,\n        -1.42723277e-01,  2.59729952e-01, -1.81025192e-02,\n        -2.77457088e-01, -5.03500029e-02,  2.12379340e-02,\n        -2.15388924e-01, -2.84164995e-01,  6.55694166e-03,\n        -2.04373017e-01,  2.61571497e-01, -5.71930483e-02,\n        -6.66431338e-02,  9.32512134e-02, -5.03665581e-02,\n         7.98572749e-02, -1.24730952e-02,  2.06023350e-01,\n         7.06658512e-02,  3.44549626e-01, -9.32558998e-02,\n         3.20867673e-02,  4.60722893e-01, -2.01058060e-01,\n         2.88202614e-01,  3.77961069e-01, -6.77379817e-02,\n         1.56027481e-01,  8.39910358e-02, -1.34850536e-02,\n        -3.02609801e-01, -5.68625778e-02, -3.42238337e-01,\n         1.40994331e-02,  1.65405422e-01, -1.08280860e-01,\n        -2.12245852e-01,  2.15223264e-02, -1.30041316e-01,\n        -2.47611150e-01,  4.70013261e-01,  2.11021323e-02,\n        -7.82447755e-02,  2.55657673e-01, -2.75754809e-01,\n        -4.55199294e-02, -2.24793106e-01, -5.52174635e-03,\n        -1.67090997e-01, -2.79362410e-01,  4.18219894e-01,\n         2.25208983e-01, -2.78037727e-01,  1.47993952e-01,\n        -2.00871140e-01, -5.36418799e-03, -8.39594454e-02,\n        -2.11747274e-01, -6.62017614e-02, -6.68109581e-02,\n         8.65863711e-02,  8.71515200e-02, -7.11286673e-03,\n        -6.66344836e-02, -4.91975427e-01,  1.62641451e-01,\n         6.10088371e-02,  1.46036372e-01, -1.21640168e-01,\n         3.61082815e-02, -2.41646051e-01, -4.96147014e-02,\n         1.75024793e-01, -2.00477261e-02,  2.65331822e-03,\n         1.38622314e-01,  5.48525214e-01, -7.75314420e-02,\n        -2.91551620e-01, -3.06438971e-02,  1.11192770e-01,\n         1.07283346e-01,  4.41179685e-02,  1.34020686e-01,\n        -2.05592692e-01, -8.75590742e-02, -1.85598001e-01,\n        -3.53112727e-01, -2.13426679e-01, -1.19583821e-02,\n         4.26900864e-01, -1.30169824e-01,  6.67276084e-02,\n         4.95786428e-01,  1.79617450e-01, -3.77661526e-01,\n         2.73280323e-01,  2.44141772e-01, -2.02567890e-01,\n        -5.59415817e-01,  1.63313225e-01, -2.38068774e-01,\n        -2.36742020e-01,  8.60238448e-02,  1.49438620e-01,\n        -1.00186996e-01, -1.75197646e-01, -5.88687372e+00,\n         9.34888422e-03,  3.55921872e-02, -1.67799994e-01,\n        -2.20044348e-02, -8.90885741e-02,  1.75055936e-02,\n         1.12002991e-01,  3.79840583e-02,  1.02477551e-01,\n         1.06410734e-01,  1.72947068e-02,  2.11392287e-02,\n         2.47263834e-01, -1.64661095e-01,  2.82909691e-01,\n         8.13377798e-02,  2.47276686e-02, -9.15621594e-02,\n        -1.32613629e-01, -1.75267920e-01, -3.03743184e-01,\n         2.28621915e-01, -9.22495723e-02, -4.27593244e-03,\n         1.39705226e-01, -2.56295167e-02, -6.31536394e-02,\n        -7.85278343e-03, -2.59414822e-01,  3.02493125e-01,\n        -9.86098945e-02, -1.23448856e-01, -8.13429058e-02,\n        -2.64657319e-01, -5.31010367e-02,  3.08039263e-02,\n         8.76912773e-02,  7.05080107e-02, -2.53301650e-01,\n        -5.22290282e-02, -3.37296128e-01, -6.29937649e-02,\n         2.08094269e-02,  1.88608333e-01,  8.56391937e-02,\n        -3.96772325e-02,  2.63312422e-02,  1.90151691e-01,\n         5.38706146e-02, -9.03353095e-02, -1.62544534e-01,\n        -3.02489877e-01, -6.72746822e-02, -1.18229315e-01,\n         1.02234527e-01,  1.03518292e-01,  2.80130714e-01,\n        -1.59880951e-01,  1.36796478e-02,  1.16239160e-01,\n        -4.85072918e-02, -1.35096252e-01, -3.28237712e-01,\n        -3.32042158e-01,  1.60710141e-01, -3.82483900e-01,\n        -4.75045443e-02,  2.68897060e-02,  3.63617450e-01,\n        -1.21051893e-01,  1.53437167e-01,  5.44450954e-02,\n        -2.53845692e-01, -3.16382311e-02, -1.82633489e-01,\n        -8.72724876e-02,  5.85974716e-02,  7.67506734e-02,\n        -3.67445350e-02, -7.34958425e-02,  1.97176233e-01,\n         9.94880870e-02,  6.64427951e-02, -1.43050298e-01,\n         3.91975567e-02,  7.63021186e-02, -1.04625523e-01,\n        -4.19027954e-02,  5.94573468e-02,  3.75587463e-01,\n        -2.41568059e-01,  2.53088564e-01,  6.18073568e-02,\n         2.59232312e-01,  1.85600877e-01,  3.93079072e-01,\n        -4.67779450e-02,  2.59628147e-01, -2.68477887e-01,\n         7.30537474e-02, -1.35486871e-01,  6.57580793e-03,\n        -1.82538763e-01,  1.67517647e-01,  1.76971212e-01,\n        -3.20802927e-01, -2.29576658e-02,  3.26218098e-01,\n         1.18426919e-01,  4.68858182e-02, -7.21635669e-02,\n        -5.95668377e-03, -4.62886184e-01, -2.43405819e-01,\n        -2.65529454e-02,  1.58378690e-01,  3.74099970e-01,\n         1.42822862e-01, -2.78408587e-01, -2.84853756e-01,\n         2.56626666e-01,  2.87897885e-01, -4.04085189e-01,\n        -6.38024628e-01, -4.83289510e-02, -9.19040069e-02,\n         6.46126345e-02, -1.22592278e-01,  7.25145712e-02,\n        -3.06122810e-01,  2.79616684e-01, -1.14105083e-01,\n        -1.54240295e-01,  1.86863959e-01, -2.02672005e-01,\n        -8.91300477e-03, -6.30364493e-02,  3.25665832e-01,\n        -1.69150922e-02,  1.13323494e-03, -9.61658359e-02,\n         1.03295565e-01,  6.00084774e-02,  5.12674004e-02,\n         5.17242774e-02,  2.64116991e-02,  8.12703595e-02,\n         3.23971063e-02, -1.09519191e-01, -1.23460516e-01,\n        -5.05832195e-01,  6.69558421e-02,  2.98151881e-01,\n        -2.38422647e-01,  2.37302944e-01,  1.09701447e-01,\n        -1.05115520e-02, -6.68317974e-02, -1.44507051e-01,\n         1.35028690e-01, -2.79485404e-01, -2.39803959e-02,\n        -1.71671435e-02, -2.80936062e-01,  3.25660288e-01,\n         4.23807651e-02,  1.71866827e-02,  1.42403878e-02,\n        -1.13528952e-01, -3.48112226e-01, -1.05658405e-01,\n         7.43695023e-03,  5.77514023e-02,  1.10539734e-01,\n         5.72628915e-01,  3.91269714e-01,  1.89319197e-02,\n         7.43936077e-02,  3.34510118e-01,  1.36006758e-01,\n         1.08156335e-02, -2.11270213e-01,  2.25188397e-02,\n         2.27828100e-01,  7.47328252e-02, -3.25340778e-03,\n         1.36925057e-01,  1.81574732e-01, -8.20306763e-02,\n        -1.17760085e-01,  5.05677424e-02,  2.83485651e-01,\n         6.11532368e-02,  3.55049372e-01, -1.07480936e-01,\n         4.05267000e-01,  3.38317692e-01, -2.38809851e-04,\n        -2.51636356e-01, -1.15347542e-02, -9.92608070e-02,\n         3.13709341e-02,  1.87988475e-01,  8.30943361e-02,\n        -8.66230056e-02, -1.02838520e-02, -5.02473339e-02,\n        -7.69946352e-02, -3.91301475e-02, -1.33120656e-01,\n        -2.44667083e-01, -6.82770386e-02,  4.19007130e-02,\n         2.95066863e-01, -1.63015351e-01,  1.55911356e-01,\n         2.00399593e-01, -2.80267626e-01,  2.31331170e-01,\n        -1.55213460e-01,  1.84762746e-01,  6.73156530e-02,\n        -1.41350910e-01,  5.99013902e-02,  2.66517073e-01,\n         2.22673252e-01, -2.47150347e-01,  8.42453837e-02,\n        -1.24953389e-01,  1.15465589e-01, -2.73876309e-01,\n         1.18918896e-01,  1.88697293e-01, -2.17251003e-01,\n        -1.12266935e-01, -1.30133331e-01, -3.15211892e-01,\n         1.28886759e-01, -1.25889089e-02, -3.05786043e-01,\n         4.13624756e-02, -1.50507495e-01, -4.49060351e-01,\n         7.39391148e-02, -4.39889319e-02, -9.55497324e-02,\n         3.23112339e-01, -1.09924078e-01,  4.60183732e-02,\n         7.75016174e-02, -7.07275942e-02,  1.67536318e-01,\n        -3.23535919e-01,  1.03226729e-01, -2.85766155e-01,\n        -2.01016515e-01, -1.73339635e-01, -3.93221170e-01,\n        -4.71513979e-02, -2.15330720e-01,  4.32753228e-02,\n         2.23527074e-01,  7.44749829e-02, -9.39065367e-02,\n         2.54611492e-01,  1.13845363e-01, -2.80111462e-01,\n         7.11833015e-02, -2.66376823e-01,  2.68345207e-01,\n        -9.60792527e-02,  3.27945530e-01,  1.34314775e-01,\n        -6.33849502e-02, -3.23654562e-01, -6.73245033e-03,\n        -8.36844817e-02,  5.26117444e-01, -6.46716058e-02,\n        -2.13634148e-01, -1.78179592e-01, -1.69252425e-01,\n        -8.65711551e-03,  1.96453944e-01, -2.11944059e-01,\n        -8.21046084e-02, -1.57479167e-01, -2.45840885e-02,\n        -1.78057358e-01,  5.41800857e-02,  2.03319062e-02,\n        -1.60061140e-02, -8.77395049e-02, -5.01807451e-01,\n         1.01021200e-01, -7.01821819e-02, -6.24573305e-02,\n        -1.62510142e-01,  3.71756330e-02, -2.56298155e-01,\n        -5.49085885e-02,  4.44702387e-01, -7.28943869e-02,\n        -9.39479247e-02,  2.88538307e-01, -2.37654466e-02,\n        -2.71990508e-01, -2.56207496e-01, -1.02508463e-01,\n        -2.41092399e-01, -2.84084231e-02,  3.41442406e-01,\n         1.31850109e-01, -3.63899767e-01, -4.50212061e-01,\n        -9.99524221e-02, -2.20329612e-01,  3.65836546e-02,\n         6.62007108e-02,  3.19025181e-02,  2.89225522e-02,\n         3.39292228e-01, -3.84429246e-02,  7.84060359e-02,\n         1.50613546e-01,  1.24354446e-02, -1.26137465e-01,\n        -7.46227130e-02, -4.32544446e-04,  1.04346424e-01,\n        -1.66081980e-01,  1.93107948e-01,  1.01084732e-01,\n        -4.73132804e-02,  3.57890546e-01, -1.78052798e-01,\n        -1.52259827e-01, -3.06655079e-01, -7.73350671e-02,\n         1.28084287e-01,  2.83102363e-01,  1.46684706e-01,\n        -8.17691535e-02, -2.46095229e-02,  1.60058737e-02,\n         1.51204512e-01,  2.92414695e-01,  4.81793642e-01,\n         3.30193102e-01,  8.44939798e-03,  2.69111216e-01,\n        -2.17076182e-01, -1.37763530e-01, -1.73923180e-01,\n         1.22173198e-01, -3.79201248e-02,  1.02935150e-01,\n         2.68751848e-02,  3.89818341e-01,  2.34836280e-01,\n         1.70755118e-01, -1.56637505e-02, -9.43020284e-02,\n        -2.36502007e-01, -1.60848722e-01,  3.09100300e-01,\n        -3.15367490e-01,  7.02861100e-02,  1.09006606e-01,\n        -6.66458011e-02, -2.84392443e-02, -1.60577133e-01,\n         4.38227728e-02, -2.12670460e-01, -7.18405992e-02,\n         7.85508081e-02,  1.64540812e-01, -9.88823026e-02,\n         1.99207733e-03, -4.14580852e-02, -1.11652210e-01,\n         1.17416829e-01, -2.50565052e-01, -1.97114944e-01,\n        -5.25079370e-02, -2.48502821e-01,  4.95425537e-02,\n         4.17074980e-03, -1.88123155e-02, -1.97011054e-01,\n        -9.82056111e-02,  2.70575821e-01, -1.95761055e-01,\n         1.19421683e-01, -1.99110866e-01, -1.78232621e-02,\n         1.05771653e-01,  5.59252858e-01,  8.88479427e-02,\n         1.34372458e-01, -5.10385692e-01,  1.39148921e-01,\n        -7.01839700e-02,  2.72529945e-02,  5.17678373e-02,\n         9.23520774e-02,  1.77895248e-01, -2.61731118e-01,\n         5.83986565e-02,  1.21166028e-01,  2.86532074e-01,\n        -2.12696150e-01, -5.91310905e-04, -1.00261986e-01,\n         7.22476020e-02,  3.57343972e-01, -5.78364320e-02,\n        -2.09309936e-01, -1.66081227e-02, -3.79870147e-01,\n        -1.35926843e-01,  2.96472371e-01, -7.12151639e-04,\n        -3.02930996e-02, -1.18424948e-02,  6.30197376e-02,\n         9.56974924e-02,  2.44312361e-01, -1.15815327e-02,\n        -5.64208552e-02,  1.59800295e-02,  8.92317891e-02,\n         1.25051156e-01, -2.65689820e-01,  3.96684594e-02,\n        -1.77558288e-01,  3.25936973e-01,  1.19713895e-01,\n         1.28910586e-01, -7.06805810e-02, -4.90561463e-02,\n         1.70417920e-01,  1.49948969e-01,  1.39230356e-01,\n        -2.31088847e-02, -8.87942500e-03, -2.50018418e-01,\n        -3.37622911e-01, -7.06694573e-02, -1.77839831e-01,\n        -1.62296727e-01,  2.08759099e-01, -4.10985239e-02,\n        -1.44695997e-01, -6.19825684e-02, -2.77821478e-02,\n        -2.14254469e-01, -2.81513155e-01, -1.23183228e-01]], dtype=float32)"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reduced['bert_features'][4904]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "                                               Title  \\\n0        aws elastic beanstalk unable access aws msk   \n1                            soap message expiration   \n2  python panda equivalent sql case statement usi...   \n3  java stack overflow error increase stack size ...   \n4               creating bitmask large number option   \n\n                                                Body  \\\n0  aws msk cluster running inside vpc subnets cre...   \n1  use time-stamp soap header implement message e...   \n2  new python trying see elegant solution time se...   \n3  running program written java eclipse program d...   \n4  android app class containing data exposed gett...   \n\n                                                Tags  \\\n0  amazon-web-services apache-kafka aws-lambda am...   \n1                  c# .net asp.net web-services soap   \n2  python sql pandas window-functions case-statement   \n3      java eclipse jvm stack-overflow jvm-arguments   \n4  java android serialization bit-manipulation bi...   \n\n                                         _clean_tags  _len_body  \\\n0  ['amazon-web-services', 'apache-kafka', 'aws-l...        786   \n1  ['c#', '.net', 'asp.net', 'web-services', 'soap']         88   \n2  ['python', 'sql', 'pandas', 'window-functions'...       1170   \n3  ['java', 'eclipse', 'jvm', 'stack-overflow', '...        592   \n4  ['java', 'android', 'serialization', 'bit-mani...        845   \n\n                                              Body_2  _len_body_2  \\\n0  aws msk cluster running inside vpc subnets cre...          765   \n1  time-stamp soap header implement message expir...           78   \n2  python elegant solution time series telematics...         1044   \n3  running program written java eclipse program d...          529   \n4  android app class containing exposed getters c...          725   \n\n                                              Body_3  \\\n0  aws msk cluster vpc subnets elastic beanstalk ...   \n1  time-stamp soap header message expiration .net...   \n2  python elegant solution time series telematics...   \n3  written java eclipse deep level recursion larg...   \n4  android app class containing exposed getters c...   \n\n                                             Title_2  \\\n0        aws elastic beanstalk unable access aws msk   \n1                            soap message expiration   \n2  python panda equivalent sql case statement usi...   \n3  java stack overflow error increase stack size ...   \n4                      creating bitmask large option   \n\n                                                Text  \\\n0  aws elastic beanstalk unable access aws msk aw...   \n1  soap message expiration use time-stamp soap he...   \n2  python panda equivalent sql case statement usi...   \n3  java stack overflow error increase stack size ...   \n4  creating bitmask large number option android a...   \n\n                                       bert_features  \n0  [[-0.21572688, 0.043502435, 0.17954159, 0.0588...  \n1  [[0.12147706, -0.4004427, 0.1871699, -0.053614...  \n2  [[-0.23494641, -0.06181486, 0.78896916, -0.110...  \n3  [[-0.034630988, -0.06871903, 0.26422969, -0.06...  \n4  [[0.0013576947, -0.20459248, 0.26405495, 0.082...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Title</th>\n      <th>Body</th>\n      <th>Tags</th>\n      <th>_clean_tags</th>\n      <th>_len_body</th>\n      <th>Body_2</th>\n      <th>_len_body_2</th>\n      <th>Body_3</th>\n      <th>Title_2</th>\n      <th>Text</th>\n      <th>bert_features</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>aws elastic beanstalk unable access aws msk</td>\n      <td>aws msk cluster running inside vpc subnets cre...</td>\n      <td>amazon-web-services apache-kafka aws-lambda am...</td>\n      <td>['amazon-web-services', 'apache-kafka', 'aws-l...</td>\n      <td>786</td>\n      <td>aws msk cluster running inside vpc subnets cre...</td>\n      <td>765</td>\n      <td>aws msk cluster vpc subnets elastic beanstalk ...</td>\n      <td>aws elastic beanstalk unable access aws msk</td>\n      <td>aws elastic beanstalk unable access aws msk aw...</td>\n      <td>[[-0.21572688, 0.043502435, 0.17954159, 0.0588...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>soap message expiration</td>\n      <td>use time-stamp soap header implement message e...</td>\n      <td>c# .net asp.net web-services soap</td>\n      <td>['c#', '.net', 'asp.net', 'web-services', 'soap']</td>\n      <td>88</td>\n      <td>time-stamp soap header implement message expir...</td>\n      <td>78</td>\n      <td>time-stamp soap header message expiration .net...</td>\n      <td>soap message expiration</td>\n      <td>soap message expiration use time-stamp soap he...</td>\n      <td>[[0.12147706, -0.4004427, 0.1871699, -0.053614...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>python panda equivalent sql case statement usi...</td>\n      <td>new python trying see elegant solution time se...</td>\n      <td>python sql pandas window-functions case-statement</td>\n      <td>['python', 'sql', 'pandas', 'window-functions'...</td>\n      <td>1170</td>\n      <td>python elegant solution time series telematics...</td>\n      <td>1044</td>\n      <td>python elegant solution time series telematics...</td>\n      <td>python panda equivalent sql case statement usi...</td>\n      <td>python panda equivalent sql case statement usi...</td>\n      <td>[[-0.23494641, -0.06181486, 0.78896916, -0.110...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>java stack overflow error increase stack size ...</td>\n      <td>running program written java eclipse program d...</td>\n      <td>java eclipse jvm stack-overflow jvm-arguments</td>\n      <td>['java', 'eclipse', 'jvm', 'stack-overflow', '...</td>\n      <td>592</td>\n      <td>running program written java eclipse program d...</td>\n      <td>529</td>\n      <td>written java eclipse deep level recursion larg...</td>\n      <td>java stack overflow error increase stack size ...</td>\n      <td>java stack overflow error increase stack size ...</td>\n      <td>[[-0.034630988, -0.06871903, 0.26422969, -0.06...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>creating bitmask large number option</td>\n      <td>android app class containing data exposed gett...</td>\n      <td>java android serialization bit-manipulation bi...</td>\n      <td>['java', 'android', 'serialization', 'bit-mani...</td>\n      <td>845</td>\n      <td>android app class containing exposed getters c...</td>\n      <td>725</td>\n      <td>android app class containing exposed getters c...</td>\n      <td>creating bitmask large option</td>\n      <td>creating bitmask large number option android a...</td>\n      <td>[[0.0013576947, -0.20459248, 0.26405495, 0.082...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reduced_index = df_reduced.reset_index(drop=True)\n",
    "df_reduced_index.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "df_reduced_index.to_csv('/Users/maurelco/Developer/Python/Projet4/data/Cleaned/df_bert_2_index.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "                                               Title  \\\n0        aws elastic beanstalk unable access aws msk   \n1                            soap message expiration   \n2  python panda equivalent sql case statement usi...   \n3  java stack overflow error increase stack size ...   \n4               creating bitmask large number option   \n5       cannot post span value document.form .submit   \n6                    cors policy issue heroku server   \n7  issue maven jetty debug eclipse breakpoints ge...   \n8      jquery form serialize multi dimensional array   \n9  react conditional rendering cs class animate s...   \n\n                                                Body  \\\n0  aws msk cluster running inside vpc subnets cre...   \n1  use time-stamp soap header implement message e...   \n2  new python trying see elegant solution time se...   \n3  running program written java eclipse program d...   \n4  android app class containing data exposed gett...   \n5  writing form use document.form .submit post va...   \n6  made client-server application backend us node...   \n7  trying debug maven project jetty server eclips...   \n8  need get value form format json post via ajax ...   \n9  using animate scroll library react-bootstrap p...   \n\n                                                Tags  \\\n0  amazon-web-services apache-kafka aws-lambda am...   \n1                  c# .net asp.net web-services soap   \n2  python sql pandas window-functions case-statement   \n3      java eclipse jvm stack-overflow jvm-arguments   \n4  java android serialization bit-manipulation bi...   \n5                javascript jquery forms http submit   \n6        javascript node.js reactjs heroku preflight   \n7                    java eclipse spring maven jetty   \n8                javascript jquery arrays json forms   \n9    css reactjs class ternary conditional-rendering   \n\n                                         _clean_tags  _len_body  \\\n0  ['amazon-web-services', 'apache-kafka', 'aws-l...        786   \n1  ['c#', '.net', 'asp.net', 'web-services', 'soap']         88   \n2  ['python', 'sql', 'pandas', 'window-functions'...       1170   \n3  ['java', 'eclipse', 'jvm', 'stack-overflow', '...        592   \n4  ['java', 'android', 'serialization', 'bit-mani...        845   \n5  ['javascript', 'jquery', 'forms', 'http', 'sub...        415   \n6  ['javascript', 'node.js', 'reactjs', 'heroku',...        446   \n7    ['java', 'eclipse', 'spring', 'maven', 'jetty']        724   \n8  ['javascript', 'jquery', 'arrays', 'json', 'fo...        679   \n9  ['css', 'reactjs', 'class', 'ternary', 'condit...        727   \n\n                                              Body_2  _len_body_2  \\\n0  aws msk cluster running inside vpc subnets cre...          765   \n1  time-stamp soap header implement message expir...           78   \n2  python elegant solution time series telematics...         1044   \n3  running program written java eclipse program d...          529   \n4  android app class containing exposed getters c...          725   \n5  writing document.form .submit post hope x http...          324   \n6  made client-server backend u node express mong...          378   \n7  debug maven project jetty server eclipse sprin...          648   \n8  get format json post via ajax format achieve i...          471   \n9  animate scroll library react-bootstrap project...          670   \n\n                                              Body_3  \\\n0  aws msk cluster vpc subnets elastic beanstalk ...   \n1  time-stamp soap header message expiration .net...   \n2  python elegant solution time series telematics...   \n3  written java eclipse deep level recursion larg...   \n4  android app class containing exposed getters c...   \n5  writing document.form .submit post hope http.f...   \n6  made client-server backend node express mongod...   \n7  maven project jetty server eclipse spring tool...   \n8  get format json post ajax format achieve id bo...   \n9  animate scroll library react-bootstrap project...   \n\n                                             Title_2  \\\n0        aws elastic beanstalk unable access aws msk   \n1                            soap message expiration   \n2  python panda equivalent sql case statement usi...   \n3  java stack overflow error increase stack size ...   \n4                      creating bitmask large option   \n5                   post value document.form .submit   \n6                          cors policy heroku server   \n7            maven jetty eclipse breakpoints skipped   \n8      jquery form serialize multi dimensional array   \n9  react conditional rendering c class animate sc...   \n\n                                                Text  \\\n0  aws elastic beanstalk unable access aws msk aw...   \n1  soap message expiration use time-stamp soap he...   \n2  python panda equivalent sql case statement usi...   \n3  java stack overflow error increase stack size ...   \n4  creating bitmask large number option android a...   \n5  cannot post span value document.form .submit w...   \n6  cors policy issue heroku server made client-se...   \n7  issue maven jetty debug eclipse breakpoints ge...   \n8  jquery form serialize multi dimensional array ...   \n9  react conditional rendering cs class animate s...   \n\n                                       bert_features  \n0  [[-0.21572688, 0.043502435, 0.17954159, 0.0588...  \n1  [[0.12147706, -0.4004427, 0.1871699, -0.053614...  \n2  [[-0.23494641, -0.06181486, 0.78896916, -0.110...  \n3  [[-0.034630988, -0.06871903, 0.26422969, -0.06...  \n4  [[0.0013576947, -0.20459248, 0.26405495, 0.082...  \n5  [[0.12432741, -0.14306657, 0.51982045, -0.0027...  \n6  [[-0.17805444, -0.32579988, 0.5416442, 0.25021...  \n7  [[-0.105132885, -0.16010264, 0.34793168, 0.112...  \n8  [[0.029572075, -0.035203893, 0.390891, -0.0481...  \n9  [[-0.1148364, 0.030055039, 0.58414066, 0.00338...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Title</th>\n      <th>Body</th>\n      <th>Tags</th>\n      <th>_clean_tags</th>\n      <th>_len_body</th>\n      <th>Body_2</th>\n      <th>_len_body_2</th>\n      <th>Body_3</th>\n      <th>Title_2</th>\n      <th>Text</th>\n      <th>bert_features</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>aws elastic beanstalk unable access aws msk</td>\n      <td>aws msk cluster running inside vpc subnets cre...</td>\n      <td>amazon-web-services apache-kafka aws-lambda am...</td>\n      <td>['amazon-web-services', 'apache-kafka', 'aws-l...</td>\n      <td>786</td>\n      <td>aws msk cluster running inside vpc subnets cre...</td>\n      <td>765</td>\n      <td>aws msk cluster vpc subnets elastic beanstalk ...</td>\n      <td>aws elastic beanstalk unable access aws msk</td>\n      <td>aws elastic beanstalk unable access aws msk aw...</td>\n      <td>[[-0.21572688, 0.043502435, 0.17954159, 0.0588...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>soap message expiration</td>\n      <td>use time-stamp soap header implement message e...</td>\n      <td>c# .net asp.net web-services soap</td>\n      <td>['c#', '.net', 'asp.net', 'web-services', 'soap']</td>\n      <td>88</td>\n      <td>time-stamp soap header implement message expir...</td>\n      <td>78</td>\n      <td>time-stamp soap header message expiration .net...</td>\n      <td>soap message expiration</td>\n      <td>soap message expiration use time-stamp soap he...</td>\n      <td>[[0.12147706, -0.4004427, 0.1871699, -0.053614...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>python panda equivalent sql case statement usi...</td>\n      <td>new python trying see elegant solution time se...</td>\n      <td>python sql pandas window-functions case-statement</td>\n      <td>['python', 'sql', 'pandas', 'window-functions'...</td>\n      <td>1170</td>\n      <td>python elegant solution time series telematics...</td>\n      <td>1044</td>\n      <td>python elegant solution time series telematics...</td>\n      <td>python panda equivalent sql case statement usi...</td>\n      <td>python panda equivalent sql case statement usi...</td>\n      <td>[[-0.23494641, -0.06181486, 0.78896916, -0.110...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>java stack overflow error increase stack size ...</td>\n      <td>running program written java eclipse program d...</td>\n      <td>java eclipse jvm stack-overflow jvm-arguments</td>\n      <td>['java', 'eclipse', 'jvm', 'stack-overflow', '...</td>\n      <td>592</td>\n      <td>running program written java eclipse program d...</td>\n      <td>529</td>\n      <td>written java eclipse deep level recursion larg...</td>\n      <td>java stack overflow error increase stack size ...</td>\n      <td>java stack overflow error increase stack size ...</td>\n      <td>[[-0.034630988, -0.06871903, 0.26422969, -0.06...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>creating bitmask large number option</td>\n      <td>android app class containing data exposed gett...</td>\n      <td>java android serialization bit-manipulation bi...</td>\n      <td>['java', 'android', 'serialization', 'bit-mani...</td>\n      <td>845</td>\n      <td>android app class containing exposed getters c...</td>\n      <td>725</td>\n      <td>android app class containing exposed getters c...</td>\n      <td>creating bitmask large option</td>\n      <td>creating bitmask large number option android a...</td>\n      <td>[[0.0013576947, -0.20459248, 0.26405495, 0.082...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>cannot post span value document.form .submit</td>\n      <td>writing form use document.form .submit post va...</td>\n      <td>javascript jquery forms http submit</td>\n      <td>['javascript', 'jquery', 'forms', 'http', 'sub...</td>\n      <td>415</td>\n      <td>writing document.form .submit post hope x http...</td>\n      <td>324</td>\n      <td>writing document.form .submit post hope http.f...</td>\n      <td>post value document.form .submit</td>\n      <td>cannot post span value document.form .submit w...</td>\n      <td>[[0.12432741, -0.14306657, 0.51982045, -0.0027...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>cors policy issue heroku server</td>\n      <td>made client-server application backend us node...</td>\n      <td>javascript node.js reactjs heroku preflight</td>\n      <td>['javascript', 'node.js', 'reactjs', 'heroku',...</td>\n      <td>446</td>\n      <td>made client-server backend u node express mong...</td>\n      <td>378</td>\n      <td>made client-server backend node express mongod...</td>\n      <td>cors policy heroku server</td>\n      <td>cors policy issue heroku server made client-se...</td>\n      <td>[[-0.17805444, -0.32579988, 0.5416442, 0.25021...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>issue maven jetty debug eclipse breakpoints ge...</td>\n      <td>trying debug maven project jetty server eclips...</td>\n      <td>java eclipse spring maven jetty</td>\n      <td>['java', 'eclipse', 'spring', 'maven', 'jetty']</td>\n      <td>724</td>\n      <td>debug maven project jetty server eclipse sprin...</td>\n      <td>648</td>\n      <td>maven project jetty server eclipse spring tool...</td>\n      <td>maven jetty eclipse breakpoints skipped</td>\n      <td>issue maven jetty debug eclipse breakpoints ge...</td>\n      <td>[[-0.105132885, -0.16010264, 0.34793168, 0.112...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>jquery form serialize multi dimensional array</td>\n      <td>need get value form format json post via ajax ...</td>\n      <td>javascript jquery arrays json forms</td>\n      <td>['javascript', 'jquery', 'arrays', 'json', 'fo...</td>\n      <td>679</td>\n      <td>get format json post via ajax format achieve i...</td>\n      <td>471</td>\n      <td>get format json post ajax format achieve id bo...</td>\n      <td>jquery form serialize multi dimensional array</td>\n      <td>jquery form serialize multi dimensional array ...</td>\n      <td>[[0.029572075, -0.035203893, 0.390891, -0.0481...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>react conditional rendering cs class animate s...</td>\n      <td>using animate scroll library react-bootstrap p...</td>\n      <td>css reactjs class ternary conditional-rendering</td>\n      <td>['css', 'reactjs', 'class', 'ternary', 'condit...</td>\n      <td>727</td>\n      <td>animate scroll library react-bootstrap project...</td>\n      <td>670</td>\n      <td>animate scroll library react-bootstrap project...</td>\n      <td>react conditional rendering c class animate sc...</td>\n      <td>react conditional rendering cs class animate s...</td>\n      <td>[[-0.1148364, 0.030055039, 0.58414066, 0.00338...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reduced_index[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "numpy.ndarray"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_reduced_index['bert_features'].iloc[0][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "pandas.core.frame.DataFrame"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_reduced_index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.21572688\n",
      "0.043502435\n",
      "0.17954159\n",
      "0.058857832\n",
      "0.027598012\n",
      "-0.0906479\n",
      "0.07839012\n",
      "0.11418236\n",
      "-0.16160877\n",
      "-0.21789217\n",
      "-0.07961099\n",
      "-0.09049707\n",
      "-0.20772885\n",
      "0.072445914\n",
      "0.01931247\n",
      "0.045401335\n",
      "-0.02223052\n",
      "-0.06178154\n",
      "0.05991511\n",
      "0.2338662\n",
      "0.13553454\n",
      "-0.04908144\n",
      "0.00051491975\n",
      "-0.14671612\n",
      "0.23569883\n",
      "-0.034861263\n",
      "-0.079125844\n",
      "-0.21549773\n",
      "-0.091943346\n",
      "-0.0749322\n",
      "0.08872671\n",
      "0.042709872\n",
      "0.11041358\n",
      "-0.11185881\n",
      "-0.13009483\n",
      "-0.09995515\n",
      "0.09717589\n",
      "0.08574437\n",
      "0.09019206\n",
      "0.051524926\n",
      "-0.14849617\n",
      "-0.40918154\n",
      "0.2216069\n",
      "0.08170135\n",
      "-0.01890817\n",
      "-0.03446816\n",
      "0.012963451\n",
      "-0.08407605\n",
      "-0.2039365\n",
      "-0.23571837\n",
      "-0.3257234\n",
      "0.07412961\n",
      "0.051341735\n",
      "0.09163191\n",
      "0.096766666\n",
      "0.045614216\n",
      "0.22460543\n",
      "-0.34785512\n",
      "-0.004863019\n",
      "-0.20837438\n",
      "0.116937704\n",
      "-0.103412844\n",
      "0.15379545\n",
      "0.21845813\n",
      "-0.009648648\n",
      "0.24164437\n",
      "-0.013546757\n",
      "0.20803122\n",
      "-0.31034708\n",
      "0.058359224\n",
      "-0.100500785\n",
      "0.16658792\n",
      "-0.04500316\n",
      "0.17709811\n",
      "0.0032225351\n",
      "-0.013581481\n",
      "-0.087754294\n",
      "0.1520344\n",
      "0.23185053\n",
      "0.045335382\n",
      "-0.08254332\n",
      "0.36221924\n",
      "-0.09587207\n",
      "-0.11756529\n",
      "0.15756501\n",
      "-0.017032394\n",
      "0.08388118\n",
      "0.04505242\n",
      "-0.2546616\n",
      "0.2788821\n",
      "0.35203785\n",
      "-0.056710493\n",
      "0.10234365\n",
      "0.026094299\n",
      "0.063066006\n",
      "-0.032393433\n",
      "-0.17205444\n",
      "0.129687\n",
      "0.099871695\n",
      "0.13290189\n",
      "-0.21297151\n",
      "0.037808903\n",
      "-0.21052033\n",
      "-0.07016468\n",
      "-0.23005646\n",
      "-0.03074165\n",
      "-0.034137104\n",
      "0.16849834\n",
      "-0.050986595\n",
      "0.27035975\n",
      "0.0011346559\n",
      "0.16903327\n",
      "-0.092541344\n",
      "-0.015322347\n",
      "-0.24537607\n",
      "-0.036024418\n",
      "-0.07063433\n",
      "-0.10650179\n",
      "0.329299\n",
      "0.030821174\n",
      "-0.09254532\n",
      "0.3134116\n",
      "-0.05154093\n",
      "0.546833\n",
      "0.05071773\n",
      "-0.011608162\n",
      "-0.19734871\n",
      "0.058124505\n",
      "0.2407855\n",
      "0.0019172244\n",
      "0.0932826\n",
      "0.05344779\n",
      "0.13867593\n",
      "-0.03276201\n",
      "-0.008222314\n",
      "0.029887855\n",
      "0.0073032924\n",
      "0.21251439\n",
      "0.0540887\n",
      "-0.17718703\n",
      "0.019031722\n",
      "-0.12512717\n",
      "0.11462101\n",
      "0.042213064\n",
      "0.028602744\n",
      "0.122490056\n",
      "-0.10307485\n",
      "0.06725389\n",
      "0.08991387\n",
      "0.31952253\n",
      "-0.02145682\n",
      "0.1358914\n",
      "0.08824801\n",
      "0.08807928\n",
      "-0.17135364\n",
      "0.060998753\n",
      "0.010550275\n",
      "-0.027452659\n",
      "-0.071611285\n",
      "0.05038394\n",
      "0.26418254\n",
      "0.23688738\n",
      "-0.254492\n",
      "0.10422421\n",
      "0.3676624\n",
      "-0.21605518\n",
      "-0.032655075\n",
      "-0.0105630765\n",
      "-0.020339996\n",
      "-0.08070893\n",
      "-0.15457521\n",
      "-0.19311298\n",
      "0.266624\n",
      "-0.06435082\n",
      "-0.23895514\n",
      "0.053961113\n",
      "0.22635761\n",
      "-0.21984434\n",
      "0.07510462\n",
      "0.11256763\n",
      "-0.16974118\n",
      "0.11032153\n",
      "0.00651254\n",
      "-0.014816923\n",
      "-0.046300944\n",
      "0.08809521\n",
      "0.1474739\n",
      "-0.0502662\n",
      "0.09745415\n",
      "0.088993214\n",
      "-0.33111855\n",
      "-0.2142195\n",
      "0.12725669\n",
      "0.105292745\n",
      "0.35245112\n",
      "-0.1701044\n",
      "-0.084640115\n",
      "0.34181187\n",
      "0.035094656\n",
      "-0.036550254\n",
      "0.60778993\n",
      "-0.14272328\n",
      "0.25972995\n",
      "-0.01810252\n",
      "-0.2774571\n",
      "-0.050350003\n",
      "0.021237934\n",
      "-0.21538892\n",
      "-0.284165\n",
      "0.0065569417\n",
      "-0.20437302\n",
      "0.2615715\n",
      "-0.05719305\n",
      "-0.066643134\n",
      "0.09325121\n",
      "-0.050366558\n",
      "0.079857275\n",
      "-0.012473095\n",
      "0.20602335\n",
      "0.07066585\n",
      "0.34454963\n",
      "-0.0932559\n",
      "0.032086767\n",
      "0.4607229\n",
      "-0.20105806\n",
      "0.2882026\n",
      "0.37796107\n",
      "-0.06773798\n",
      "0.15602748\n",
      "0.083991036\n",
      "-0.013485054\n",
      "-0.3026098\n",
      "-0.056862578\n",
      "-0.34223834\n",
      "0.014099433\n",
      "0.16540542\n",
      "-0.10828086\n",
      "-0.21224585\n",
      "0.021522326\n",
      "-0.13004132\n",
      "-0.24761115\n",
      "0.47001326\n",
      "0.021102132\n",
      "-0.078244776\n",
      "0.25565767\n",
      "-0.2757548\n",
      "-0.04551993\n",
      "-0.2247931\n",
      "-0.0055217464\n",
      "-0.167091\n",
      "-0.2793624\n",
      "0.4182199\n",
      "0.22520898\n",
      "-0.27803773\n",
      "0.14799395\n",
      "-0.20087114\n",
      "-0.005364188\n",
      "-0.083959445\n",
      "-0.21174727\n",
      "-0.06620176\n",
      "-0.06681096\n",
      "0.08658637\n",
      "0.08715152\n",
      "-0.0071128667\n",
      "-0.06663448\n",
      "-0.49197543\n",
      "0.16264145\n",
      "0.061008837\n",
      "0.14603637\n",
      "-0.12164017\n",
      "0.03610828\n",
      "-0.24164605\n",
      "-0.0496147\n",
      "0.1750248\n",
      "-0.020047726\n",
      "0.0026533182\n",
      "0.13862231\n",
      "0.5485252\n",
      "-0.07753144\n",
      "-0.29155162\n",
      "-0.030643897\n",
      "0.11119277\n",
      "0.10728335\n",
      "0.04411797\n",
      "0.13402069\n",
      "-0.20559269\n",
      "-0.087559074\n",
      "-0.185598\n",
      "-0.35311273\n",
      "-0.21342668\n",
      "-0.011958382\n",
      "0.42690086\n",
      "-0.13016982\n",
      "0.06672761\n",
      "0.49578643\n",
      "0.17961745\n",
      "-0.37766153\n",
      "0.27328032\n",
      "0.24414177\n",
      "-0.20256789\n",
      "-0.5594158\n",
      "0.16331322\n",
      "-0.23806877\n",
      "-0.23674202\n",
      "0.086023845\n",
      "0.14943862\n",
      "-0.100186996\n",
      "-0.17519765\n",
      "-5.8868737\n",
      "0.009348884\n",
      "0.035592187\n",
      "-0.1678\n",
      "-0.022004435\n",
      "-0.089088574\n",
      "0.017505594\n",
      "0.11200299\n",
      "0.03798406\n",
      "0.10247755\n",
      "0.106410734\n",
      "0.017294707\n",
      "0.021139229\n",
      "0.24726383\n",
      "-0.1646611\n",
      "0.2829097\n",
      "0.08133778\n",
      "0.024727669\n",
      "-0.09156216\n",
      "-0.13261363\n",
      "-0.17526792\n",
      "-0.30374318\n",
      "0.22862191\n",
      "-0.09224957\n",
      "-0.0042759324\n",
      "0.13970523\n",
      "-0.025629517\n",
      "-0.06315364\n",
      "-0.007852783\n",
      "-0.25941482\n",
      "0.30249313\n",
      "-0.098609895\n",
      "-0.123448856\n",
      "-0.081342906\n",
      "-0.26465732\n",
      "-0.053101037\n",
      "0.030803926\n",
      "0.08769128\n",
      "0.07050801\n",
      "-0.25330165\n",
      "-0.05222903\n",
      "-0.33729613\n",
      "-0.062993765\n",
      "0.020809427\n",
      "0.18860833\n",
      "0.08563919\n",
      "-0.039677233\n",
      "0.026331242\n",
      "0.19015169\n",
      "0.053870615\n",
      "-0.09033531\n",
      "-0.16254453\n",
      "-0.30248988\n",
      "-0.06727468\n",
      "-0.118229315\n",
      "0.10223453\n",
      "0.10351829\n",
      "0.2801307\n",
      "-0.15988095\n",
      "0.013679648\n",
      "0.11623916\n",
      "-0.04850729\n",
      "-0.13509625\n",
      "-0.3282377\n",
      "-0.33204216\n",
      "0.16071014\n",
      "-0.3824839\n",
      "-0.047504544\n",
      "0.026889706\n",
      "0.36361745\n",
      "-0.12105189\n",
      "0.15343717\n",
      "0.054445095\n",
      "-0.2538457\n",
      "-0.03163823\n",
      "-0.18263349\n",
      "-0.08727249\n",
      "0.05859747\n",
      "0.07675067\n",
      "-0.036744535\n",
      "-0.07349584\n",
      "0.19717623\n",
      "0.09948809\n",
      "0.066442795\n",
      "-0.1430503\n",
      "0.039197557\n",
      "0.07630212\n",
      "-0.10462552\n",
      "-0.041902795\n",
      "0.059457347\n",
      "0.37558746\n",
      "-0.24156806\n",
      "0.25308856\n",
      "0.061807357\n",
      "0.2592323\n",
      "0.18560088\n",
      "0.39307907\n",
      "-0.046777945\n",
      "0.25962815\n",
      "-0.2684779\n",
      "0.07305375\n",
      "-0.13548687\n",
      "0.006575808\n",
      "-0.18253876\n",
      "0.16751765\n",
      "0.17697121\n",
      "-0.32080293\n",
      "-0.022957666\n",
      "0.3262181\n",
      "0.11842692\n",
      "0.04688582\n",
      "-0.07216357\n",
      "-0.005956684\n",
      "-0.46288618\n",
      "-0.24340582\n",
      "-0.026552945\n",
      "0.15837869\n",
      "0.37409997\n",
      "0.14282286\n",
      "-0.2784086\n",
      "-0.28485376\n",
      "0.25662667\n",
      "0.28789788\n",
      "-0.4040852\n",
      "-0.6380246\n",
      "-0.04832895\n",
      "-0.09190401\n",
      "0.064612634\n",
      "-0.12259228\n",
      "0.07251457\n",
      "-0.3061228\n",
      "0.27961668\n",
      "-0.11410508\n",
      "-0.1542403\n",
      "0.18686396\n",
      "-0.202672\n",
      "-0.008913005\n",
      "-0.06303645\n",
      "0.32566583\n",
      "-0.016915092\n",
      "0.0011332349\n",
      "-0.096165836\n",
      "0.103295565\n",
      "0.060008477\n",
      "0.0512674\n",
      "0.051724277\n",
      "0.0264117\n",
      "0.08127036\n",
      "0.032397106\n",
      "-0.10951919\n",
      "-0.12346052\n",
      "-0.5058322\n",
      "0.06695584\n",
      "0.29815188\n",
      "-0.23842265\n",
      "0.23730294\n",
      "0.10970145\n",
      "-0.010511552\n",
      "-0.0668318\n",
      "-0.14450705\n",
      "0.13502869\n",
      "-0.2794854\n",
      "-0.023980396\n",
      "-0.017167144\n",
      "-0.28093606\n",
      "0.3256603\n",
      "0.042380765\n",
      "0.017186683\n",
      "0.014240388\n",
      "-0.11352895\n",
      "-0.34811223\n",
      "-0.105658405\n",
      "0.00743695\n",
      "0.057751402\n",
      "0.110539734\n",
      "0.5726289\n",
      "0.3912697\n",
      "0.01893192\n",
      "0.07439361\n",
      "0.33451012\n",
      "0.13600676\n",
      "0.010815633\n",
      "-0.21127021\n",
      "0.02251884\n",
      "0.2278281\n",
      "0.074732825\n",
      "-0.0032534078\n",
      "0.13692506\n",
      "0.18157473\n",
      "-0.08203068\n",
      "-0.117760085\n",
      "0.050567742\n",
      "0.28348565\n",
      "0.061153237\n",
      "0.35504937\n",
      "-0.107480936\n",
      "0.405267\n",
      "0.3383177\n",
      "-0.00023880985\n",
      "-0.25163636\n",
      "-0.011534754\n",
      "-0.09926081\n",
      "0.031370934\n",
      "0.18798847\n",
      "0.083094336\n",
      "-0.086623006\n",
      "-0.010283852\n",
      "-0.050247334\n",
      "-0.076994635\n",
      "-0.039130148\n",
      "-0.13312066\n",
      "-0.24466708\n",
      "-0.06827704\n",
      "0.041900713\n",
      "0.29506686\n",
      "-0.16301535\n",
      "0.15591136\n",
      "0.20039959\n",
      "-0.28026763\n",
      "0.23133117\n",
      "-0.15521346\n",
      "0.18476275\n",
      "0.06731565\n",
      "-0.14135091\n",
      "0.05990139\n",
      "0.26651707\n",
      "0.22267325\n",
      "-0.24715035\n",
      "0.084245384\n",
      "-0.12495339\n",
      "0.11546559\n",
      "-0.2738763\n",
      "0.118918896\n",
      "0.1886973\n",
      "-0.217251\n",
      "-0.112266935\n",
      "-0.13013333\n",
      "-0.3152119\n",
      "0.12888676\n",
      "-0.012588909\n",
      "-0.30578604\n",
      "0.041362476\n",
      "-0.1505075\n",
      "-0.44906035\n",
      "0.073939115\n",
      "-0.043988932\n",
      "-0.09554973\n",
      "0.32311234\n",
      "-0.10992408\n",
      "0.046018373\n",
      "0.07750162\n",
      "-0.070727594\n",
      "0.16753632\n",
      "-0.32353592\n",
      "0.10322673\n",
      "-0.28576615\n",
      "-0.20101652\n",
      "-0.17333964\n",
      "-0.39322117\n",
      "-0.047151398\n",
      "-0.21533072\n",
      "0.043275323\n",
      "0.22352707\n",
      "0.07447498\n",
      "-0.09390654\n",
      "0.2546115\n",
      "0.11384536\n",
      "-0.28011146\n",
      "0.0711833\n",
      "-0.26637682\n",
      "0.2683452\n",
      "-0.09607925\n",
      "0.32794553\n",
      "0.13431478\n",
      "-0.06338495\n",
      "-0.32365456\n",
      "-0.0067324503\n",
      "-0.08368448\n",
      "0.52611744\n",
      "-0.064671606\n",
      "-0.21363415\n",
      "-0.17817959\n",
      "-0.16925243\n",
      "-0.0086571155\n",
      "0.19645394\n",
      "-0.21194406\n",
      "-0.08210461\n",
      "-0.15747917\n",
      "-0.024584088\n",
      "-0.17805736\n",
      "0.054180086\n",
      "0.020331906\n",
      "-0.016006114\n",
      "-0.087739505\n",
      "-0.50180745\n",
      "0.1010212\n",
      "-0.07018218\n",
      "-0.06245733\n",
      "-0.16251014\n",
      "0.037175633\n",
      "-0.25629815\n",
      "-0.05490859\n",
      "0.4447024\n",
      "-0.07289439\n",
      "-0.093947925\n",
      "0.2885383\n",
      "-0.023765447\n",
      "-0.2719905\n",
      "-0.2562075\n",
      "-0.10250846\n",
      "-0.2410924\n",
      "-0.028408423\n",
      "0.3414424\n",
      "0.13185011\n",
      "-0.36389977\n",
      "-0.45021206\n",
      "-0.09995242\n",
      "-0.22032961\n",
      "0.036583655\n",
      "0.06620071\n",
      "0.031902518\n",
      "0.028922552\n",
      "0.33929223\n",
      "-0.038442925\n",
      "0.078406036\n",
      "0.15061355\n",
      "0.012435445\n",
      "-0.12613747\n",
      "-0.07462271\n",
      "-0.00043254445\n",
      "0.104346424\n",
      "-0.16608198\n",
      "0.19310795\n",
      "0.10108473\n",
      "-0.04731328\n",
      "0.35789055\n",
      "-0.1780528\n",
      "-0.15225983\n",
      "-0.30665508\n",
      "-0.07733507\n",
      "0.12808429\n",
      "0.28310236\n",
      "0.1466847\n",
      "-0.08176915\n",
      "-0.024609523\n",
      "0.016005874\n",
      "0.15120451\n",
      "0.2924147\n",
      "0.48179364\n",
      "0.3301931\n",
      "0.008449398\n",
      "0.26911122\n",
      "-0.21707618\n",
      "-0.13776353\n",
      "-0.17392318\n",
      "0.1221732\n",
      "-0.037920125\n",
      "0.10293515\n",
      "0.026875185\n",
      "0.38981834\n",
      "0.23483628\n",
      "0.17075512\n",
      "-0.01566375\n",
      "-0.09430203\n",
      "-0.236502\n",
      "-0.16084872\n",
      "0.3091003\n",
      "-0.3153675\n",
      "0.07028611\n",
      "0.109006606\n",
      "-0.0666458\n",
      "-0.028439244\n",
      "-0.16057713\n",
      "0.043822773\n",
      "-0.21267046\n",
      "-0.0718406\n",
      "0.07855081\n",
      "0.16454081\n",
      "-0.0988823\n",
      "0.0019920773\n",
      "-0.041458085\n",
      "-0.11165221\n",
      "0.11741683\n",
      "-0.25056505\n",
      "-0.19711494\n",
      "-0.052507937\n",
      "-0.24850282\n",
      "0.049542554\n",
      "0.00417075\n",
      "-0.018812316\n",
      "-0.19701105\n",
      "-0.09820561\n",
      "0.27057582\n",
      "-0.19576105\n",
      "0.11942168\n",
      "-0.19911087\n",
      "-0.017823262\n",
      "0.10577165\n",
      "0.55925286\n",
      "0.08884794\n",
      "0.13437246\n",
      "-0.5103857\n",
      "0.13914892\n",
      "-0.07018397\n",
      "0.027252994\n",
      "0.051767837\n",
      "0.09235208\n",
      "0.17789525\n",
      "-0.26173112\n",
      "0.058398657\n",
      "0.12116603\n",
      "0.28653207\n",
      "-0.21269615\n",
      "-0.0005913109\n",
      "-0.100261986\n",
      "0.0722476\n",
      "0.35734397\n",
      "-0.057836432\n",
      "-0.20930994\n",
      "-0.016608123\n",
      "-0.37987015\n",
      "-0.13592684\n",
      "0.29647237\n",
      "-0.00071215164\n",
      "-0.0302931\n",
      "-0.011842495\n",
      "0.06301974\n",
      "0.09569749\n",
      "0.24431236\n",
      "-0.011581533\n",
      "-0.056420855\n",
      "0.01598003\n",
      "0.08923179\n",
      "0.12505116\n",
      "-0.26568982\n",
      "0.03966846\n",
      "-0.17755829\n",
      "0.32593697\n",
      "0.119713895\n",
      "0.12891059\n",
      "-0.07068058\n",
      "-0.049056146\n",
      "0.17041792\n",
      "0.14994897\n",
      "0.13923036\n",
      "-0.023108885\n",
      "-0.008879425\n",
      "-0.25001842\n",
      "-0.3376229\n",
      "-0.07066946\n",
      "-0.17783983\n",
      "-0.16229673\n",
      "0.2087591\n",
      "-0.041098524\n",
      "-0.144696\n",
      "-0.06198257\n",
      "-0.027782148\n",
      "-0.21425447\n",
      "-0.28151315\n",
      "-0.12318323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n",
      "/var/folders/lf/xpbzxzn13ss6xxtstbmn6t540000gn/T/ipykernel_69077/2835351307.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[str(nbr)] = nbr\n"
     ]
    },
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [-0.21572688, 0.043502435, 0.17954159, 0.058857832, 0.027598012, -0.0906479, 0.07839012, 0.11418236, -0.16160877, -0.21789217, -0.07961099, -0.09049707, -0.20772885, 0.072445914, 0.01931247, 0.045401335, -0.02223052, -0.06178154, 0.05991511, 0.2338662, 0.13553454, -0.04908144, 0.00051491975, -0.14671612, 0.23569883, -0.034861263, -0.079125844, -0.21549773, -0.091943346, -0.0749322, 0.08872671, 0.042709872, 0.11041358, -0.11185881, -0.13009483, -0.09995515, 0.09717589, 0.08574437, 0.09019206, 0.051524926, -0.14849617, -0.40918154, 0.2216069, 0.08170135, -0.01890817, -0.03446816, 0.012963451, -0.08407605, -0.2039365, -0.23571837, -0.3257234, 0.07412961, 0.051341735, 0.09163191, 0.096766666, 0.045614216, 0.22460543, -0.34785512, -0.004863019, -0.20837438, 0.116937704, -0.103412844, 0.15379545, 0.21845813, -0.009648648, 0.24164437, -0.013546757, 0.20803122, -0.31034708, 0.058359224, -0.100500785, 0.16658792, -0.04500316, 0.17709811, 0.0032225351, -0.013581481, -0.087754294, 0.1520344, 0.23185053, 0.045335382, -0.08254332, 0.36221924, -0.09587207, -0.11756529, 0.15756501, -0.017032394, 0.08388118, 0.04505242, -0.2546616, 0.2788821, 0.35203785, -0.056710493, 0.10234365, 0.026094299, 0.063066006, -0.032393433, -0.17205444, 0.129687, 0.099871695, 0.13290189, ...]\nIndex: []\n\n[0 rows x 768 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>-0.21572688</th>\n      <th>0.043502435</th>\n      <th>0.17954159</th>\n      <th>0.058857832</th>\n      <th>0.027598012</th>\n      <th>-0.0906479</th>\n      <th>0.07839012</th>\n      <th>0.11418236</th>\n      <th>-0.16160877</th>\n      <th>-0.21789217</th>\n      <th>...</th>\n      <th>-0.17783983</th>\n      <th>-0.16229673</th>\n      <th>0.2087591</th>\n      <th>-0.041098524</th>\n      <th>-0.144696</th>\n      <th>-0.06198257</th>\n      <th>-0.027782148</th>\n      <th>-0.21425447</th>\n      <th>-0.28151315</th>\n      <th>-0.12318323</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n<p>0 rows Ã— 768 columns</p>\n</div>"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.DataFrame()\n",
    "for index, row in df_reduced_index.iterrows():\n",
    "    for nbr in row['bert_features'][0]:\n",
    "        df_test[str(nbr)] = nbr\n",
    "        print(nbr)\n",
    "    break\n",
    "df_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method index of str object at 0x17d6ff2b0>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[65], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m index \u001B[38;5;241m=\u001B[39m row\u001B[38;5;241m.\u001B[39mindex\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(index)\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m number \u001B[38;5;129;01min\u001B[39;00m \u001B[43mrow\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbert_features\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m[\u001B[38;5;241m0\u001B[39m]:\n\u001B[1;32m      6\u001B[0m     df_test[\u001B[38;5;28mstr\u001B[39m(index)] \u001B[38;5;241m=\u001B[39m number\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;28mprint\u001B[39m(df_test)\n",
      "\u001B[0;31mTypeError\u001B[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "df_test = pd.DataFrame()\n",
    "for row in df_reduced_index:\n",
    "    index = row.index\n",
    "    print(index)\n",
    "    for number in row['bert_features'][0]:\n",
    "        print()\n",
    "        df_test[str(index)] = number\n",
    "        print(df_test)\n",
    "df_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "        0         1         2         3         4         5         6    \\\n0 -0.215727  0.043502  0.179542  0.058858  0.027598 -0.090648  0.078390   \n1  0.121477 -0.400443  0.187170 -0.053614  0.032749  0.000322  0.306325   \n2 -0.234946 -0.061815  0.788969 -0.110014  0.210104  0.129901  0.126037   \n3 -0.034631 -0.068719  0.264230 -0.068252 -0.123401  0.053684  0.335138   \n4  0.001358 -0.204592  0.264055  0.082364 -0.015501  0.090622  0.162963   \n5  0.124327 -0.143067  0.519820 -0.002744 -0.117512  0.020493  0.230854   \n6 -0.178054 -0.325800  0.541644  0.250217  0.008692 -0.013846  0.253489   \n7 -0.105133 -0.160103  0.347932  0.112888  0.067959 -0.036901  0.078830   \n8  0.029572 -0.035204  0.390891 -0.048121 -0.117691  0.009252  0.075095   \n9 -0.114836  0.030055  0.584141  0.003384 -0.198603  0.050538  0.182209   \n\n        7         8         9    ...       758       759       760       761  \\\n0  0.114182 -0.161609 -0.217892  ... -0.177840 -0.162297  0.208759 -0.041099   \n1  0.021682  0.566741 -0.467160  ...  0.554395 -0.002612 -0.321709 -0.170809   \n2 -0.062534  0.044446 -0.216005  ...  0.283546 -0.216788  0.063644  0.176989   \n3 -0.112122 -0.089687 -0.228471  ...  0.153363  0.148677 -0.103926  0.065526   \n4  0.034477  0.067243 -0.141813  ...  0.057984 -0.131619  0.083216  0.048955   \n5 -0.149212  0.288023 -0.445608  ...  0.245649 -0.164215  0.035716 -0.162459   \n6  0.019093  0.194239 -0.371500  ...  0.169655 -0.336040 -0.040717 -0.049057   \n7 -0.000529 -0.008918 -0.307232  ...  0.174186 -0.086237 -0.056321 -0.156031   \n8  0.008413  0.287546 -0.176414  ...  0.179898 -0.254565  0.241240  0.004733   \n9 -0.217037  0.269912 -0.298112  ...  0.014986 -0.170390  0.151955  0.097300   \n\n        762       763       764       765       766       767  \n0 -0.144696 -0.061983 -0.027782 -0.214254 -0.281513 -0.123183  \n1  0.122298  0.270569  0.421899 -0.231104 -0.072635  0.064898  \n2  0.094684  0.140148 -0.436885 -0.431566 -0.221282 -0.163208  \n3 -0.097703 -0.080886  0.028180 -0.284574 -0.206623 -0.052170  \n4 -0.059507  0.141958  0.063569 -0.227975 -0.352300  0.163431  \n5 -0.118479  0.091894 -0.100448 -0.180576 -0.120428  0.109715  \n6 -0.073372  0.022485  0.032912 -0.338772 -0.082635  0.026120  \n7 -0.009143  0.040110 -0.029092 -0.210842 -0.218994  0.048816  \n8  0.005038  0.003700 -0.131069 -0.313527 -0.039836  0.006855  \n9  0.017388 -0.128568 -0.096577 -0.412008 -0.170671  0.066363  \n\n[10 rows x 768 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>758</th>\n      <th>759</th>\n      <th>760</th>\n      <th>761</th>\n      <th>762</th>\n      <th>763</th>\n      <th>764</th>\n      <th>765</th>\n      <th>766</th>\n      <th>767</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.215727</td>\n      <td>0.043502</td>\n      <td>0.179542</td>\n      <td>0.058858</td>\n      <td>0.027598</td>\n      <td>-0.090648</td>\n      <td>0.078390</td>\n      <td>0.114182</td>\n      <td>-0.161609</td>\n      <td>-0.217892</td>\n      <td>...</td>\n      <td>-0.177840</td>\n      <td>-0.162297</td>\n      <td>0.208759</td>\n      <td>-0.041099</td>\n      <td>-0.144696</td>\n      <td>-0.061983</td>\n      <td>-0.027782</td>\n      <td>-0.214254</td>\n      <td>-0.281513</td>\n      <td>-0.123183</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.121477</td>\n      <td>-0.400443</td>\n      <td>0.187170</td>\n      <td>-0.053614</td>\n      <td>0.032749</td>\n      <td>0.000322</td>\n      <td>0.306325</td>\n      <td>0.021682</td>\n      <td>0.566741</td>\n      <td>-0.467160</td>\n      <td>...</td>\n      <td>0.554395</td>\n      <td>-0.002612</td>\n      <td>-0.321709</td>\n      <td>-0.170809</td>\n      <td>0.122298</td>\n      <td>0.270569</td>\n      <td>0.421899</td>\n      <td>-0.231104</td>\n      <td>-0.072635</td>\n      <td>0.064898</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.234946</td>\n      <td>-0.061815</td>\n      <td>0.788969</td>\n      <td>-0.110014</td>\n      <td>0.210104</td>\n      <td>0.129901</td>\n      <td>0.126037</td>\n      <td>-0.062534</td>\n      <td>0.044446</td>\n      <td>-0.216005</td>\n      <td>...</td>\n      <td>0.283546</td>\n      <td>-0.216788</td>\n      <td>0.063644</td>\n      <td>0.176989</td>\n      <td>0.094684</td>\n      <td>0.140148</td>\n      <td>-0.436885</td>\n      <td>-0.431566</td>\n      <td>-0.221282</td>\n      <td>-0.163208</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.034631</td>\n      <td>-0.068719</td>\n      <td>0.264230</td>\n      <td>-0.068252</td>\n      <td>-0.123401</td>\n      <td>0.053684</td>\n      <td>0.335138</td>\n      <td>-0.112122</td>\n      <td>-0.089687</td>\n      <td>-0.228471</td>\n      <td>...</td>\n      <td>0.153363</td>\n      <td>0.148677</td>\n      <td>-0.103926</td>\n      <td>0.065526</td>\n      <td>-0.097703</td>\n      <td>-0.080886</td>\n      <td>0.028180</td>\n      <td>-0.284574</td>\n      <td>-0.206623</td>\n      <td>-0.052170</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.001358</td>\n      <td>-0.204592</td>\n      <td>0.264055</td>\n      <td>0.082364</td>\n      <td>-0.015501</td>\n      <td>0.090622</td>\n      <td>0.162963</td>\n      <td>0.034477</td>\n      <td>0.067243</td>\n      <td>-0.141813</td>\n      <td>...</td>\n      <td>0.057984</td>\n      <td>-0.131619</td>\n      <td>0.083216</td>\n      <td>0.048955</td>\n      <td>-0.059507</td>\n      <td>0.141958</td>\n      <td>0.063569</td>\n      <td>-0.227975</td>\n      <td>-0.352300</td>\n      <td>0.163431</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.124327</td>\n      <td>-0.143067</td>\n      <td>0.519820</td>\n      <td>-0.002744</td>\n      <td>-0.117512</td>\n      <td>0.020493</td>\n      <td>0.230854</td>\n      <td>-0.149212</td>\n      <td>0.288023</td>\n      <td>-0.445608</td>\n      <td>...</td>\n      <td>0.245649</td>\n      <td>-0.164215</td>\n      <td>0.035716</td>\n      <td>-0.162459</td>\n      <td>-0.118479</td>\n      <td>0.091894</td>\n      <td>-0.100448</td>\n      <td>-0.180576</td>\n      <td>-0.120428</td>\n      <td>0.109715</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>-0.178054</td>\n      <td>-0.325800</td>\n      <td>0.541644</td>\n      <td>0.250217</td>\n      <td>0.008692</td>\n      <td>-0.013846</td>\n      <td>0.253489</td>\n      <td>0.019093</td>\n      <td>0.194239</td>\n      <td>-0.371500</td>\n      <td>...</td>\n      <td>0.169655</td>\n      <td>-0.336040</td>\n      <td>-0.040717</td>\n      <td>-0.049057</td>\n      <td>-0.073372</td>\n      <td>0.022485</td>\n      <td>0.032912</td>\n      <td>-0.338772</td>\n      <td>-0.082635</td>\n      <td>0.026120</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>-0.105133</td>\n      <td>-0.160103</td>\n      <td>0.347932</td>\n      <td>0.112888</td>\n      <td>0.067959</td>\n      <td>-0.036901</td>\n      <td>0.078830</td>\n      <td>-0.000529</td>\n      <td>-0.008918</td>\n      <td>-0.307232</td>\n      <td>...</td>\n      <td>0.174186</td>\n      <td>-0.086237</td>\n      <td>-0.056321</td>\n      <td>-0.156031</td>\n      <td>-0.009143</td>\n      <td>0.040110</td>\n      <td>-0.029092</td>\n      <td>-0.210842</td>\n      <td>-0.218994</td>\n      <td>0.048816</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.029572</td>\n      <td>-0.035204</td>\n      <td>0.390891</td>\n      <td>-0.048121</td>\n      <td>-0.117691</td>\n      <td>0.009252</td>\n      <td>0.075095</td>\n      <td>0.008413</td>\n      <td>0.287546</td>\n      <td>-0.176414</td>\n      <td>...</td>\n      <td>0.179898</td>\n      <td>-0.254565</td>\n      <td>0.241240</td>\n      <td>0.004733</td>\n      <td>0.005038</td>\n      <td>0.003700</td>\n      <td>-0.131069</td>\n      <td>-0.313527</td>\n      <td>-0.039836</td>\n      <td>0.006855</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>-0.114836</td>\n      <td>0.030055</td>\n      <td>0.584141</td>\n      <td>0.003384</td>\n      <td>-0.198603</td>\n      <td>0.050538</td>\n      <td>0.182209</td>\n      <td>-0.217037</td>\n      <td>0.269912</td>\n      <td>-0.298112</td>\n      <td>...</td>\n      <td>0.014986</td>\n      <td>-0.170390</td>\n      <td>0.151955</td>\n      <td>0.097300</td>\n      <td>0.017388</td>\n      <td>-0.128568</td>\n      <td>-0.096577</td>\n      <td>-0.412008</td>\n      <td>-0.170671</td>\n      <td>0.066363</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows Ã— 768 columns</p>\n</div>"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the data from the 'Bert_features' column\n",
    "bert_features = df_reduced_index['bert_features'].tolist()\n",
    "\n",
    "# Convert the nested numpy arrays into a list of lists\n",
    "bert_features = [[val for val in inner_array[0]] for inner_array in bert_features]\n",
    "\n",
    "# Create the new DataFrame\n",
    "new_df = pd.DataFrame.from_records(bert_features)\n",
    "new_df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "(24180, 768)"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "new_df.to_csv('/Users/maurelco/Developer/Python/Projet4/data/Cleaned/df_bert_embedding_matrix.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "clf_text = MultiOutputClassifier(LogisticRegression(n_jobs=-1, max_iter= 200),n_jobs=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "clf_title = MultiOutputClassifier(LogisticRegression(n_jobs=-1, max_iter= 200),n_jobs=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "(25427, 231)"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "<25427x95 sparse matrix of type '<class 'numpy.float64'>'\n\twith 202841 stored elements in Compressed Sparse Row format>"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf_title"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "        c#  javascript  java  python  php  html  jquery  .net  asp.net  \\\n29520  0.0         0.0   0.0     0.0  1.0   0.0     0.0   0.0      0.0   \n37194  0.0         0.0   0.0     0.0  0.0   0.0     0.0   0.0      0.0   \n39055  0.0         0.0   0.0     0.0  0.0   0.0     0.0   1.0      0.0   \n39251  0.0         0.0   0.0     0.0  0.0   0.0     0.0   0.0      0.0   \n26072  0.0         0.0   0.0     0.0  0.0   0.0     0.0   0.0      0.0   \n...    ...         ...   ...     ...  ...   ...     ...   ...      ...   \n22229  0.0         0.0   0.0     0.0  0.0   0.0     0.0   0.0      0.0   \n1350   1.0         0.0   0.0     0.0  0.0   0.0     0.0   0.0      0.0   \n45472  0.0         0.0   1.0     0.0  0.0   0.0     0.0   0.0      0.0   \n24371  0.0         0.0   1.0     0.0  0.0   0.0     0.0   0.0      0.0   \n5930   0.0         0.0   0.0     0.0  0.0   0.0     0.0   0.0      0.0   \n\n       android  ...  cookies  webpack  dynamic  android-fragments  for-loop  \\\n29520      0.0  ...      0.0      0.0      0.0                0.0       0.0   \n37194      0.0  ...      0.0      0.0      0.0                0.0       0.0   \n39055      0.0  ...      0.0      0.0      0.0                0.0       0.0   \n39251      0.0  ...      0.0      0.0      0.0                0.0       0.0   \n26072      0.0  ...      0.0      0.0      0.0                0.0       0.0   \n...        ...  ...      ...      ...      ...                ...       ...   \n22229      0.0  ...      0.0      0.0      0.0                0.0       0.0   \n1350       0.0  ...      0.0      0.0      0.0                0.0       0.0   \n45472      0.0  ...      0.0      0.0      0.0                0.0       0.0   \n24371      0.0  ...      0.0      0.0      0.0                0.0       0.0   \n5930       0.0  ...      0.0      0.0      0.0                0.0       0.0   \n\n       sharepoint  codeigniter  pyqt  jsf  windows-phone  \n29520         0.0          0.0   0.0  0.0            0.0  \n37194         0.0          0.0   0.0  0.0            0.0  \n39055         0.0          0.0   0.0  0.0            0.0  \n39251         0.0          0.0   0.0  0.0            0.0  \n26072         0.0          0.0   0.0  0.0            0.0  \n...           ...          ...   ...  ...            ...  \n22229         0.0          0.0   0.0  0.0            0.0  \n1350          0.0          0.0   0.0  0.0            0.0  \n45472         0.0          0.0   0.0  0.0            0.0  \n24371         0.0          0.0   0.0  0.0            0.0  \n5930          0.0          0.0   0.0  0.0            0.0  \n\n[25427 rows x 231 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>c#</th>\n      <th>javascript</th>\n      <th>java</th>\n      <th>python</th>\n      <th>php</th>\n      <th>html</th>\n      <th>jquery</th>\n      <th>.net</th>\n      <th>asp.net</th>\n      <th>android</th>\n      <th>...</th>\n      <th>cookies</th>\n      <th>webpack</th>\n      <th>dynamic</th>\n      <th>android-fragments</th>\n      <th>for-loop</th>\n      <th>sharepoint</th>\n      <th>codeigniter</th>\n      <th>pyqt</th>\n      <th>jsf</th>\n      <th>windows-phone</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>29520</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>37194</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>39055</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>39251</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>26072</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>22229</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1350</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>45472</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>24371</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5930</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>25427 rows Ã— 231 columns</p>\n</div>"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "MultiOutputClassifier(estimator=LogisticRegression(max_iter=200, n_jobs=-1),\n                      n_jobs=-1)",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputClassifier(estimator=LogisticRegression(max_iter=200, n_jobs=-1),\n                      n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=LogisticRegression(max_iter=200, n_jobs=-1),\n                      n_jobs=-1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=200, n_jobs=-1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=200, n_jobs=-1)</pre></div></div></div></div></div></div></div></div></div></div>"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_title = clf_title.fit(X_train_tfidf_title, y_train)\n",
    "clf_title"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "MultiOutputClassifier(estimator=LogisticRegression(max_iter=200, n_jobs=-1),\n                      n_jobs=-1)",
      "text/html": "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputClassifier(estimator=LogisticRegression(max_iter=200, n_jobs=-1),\n                      n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=LogisticRegression(max_iter=200, n_jobs=-1),\n                      n_jobs=-1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=200, n_jobs=-1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=200, n_jobs=-1)</pre></div></div></div></div></div></div></div></div></div></div>"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_text = clf_text.fit(X_train_tfidf_text, y_train)\n",
    "clf_text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "y_pred_train_text = clf_text.predict(X_train_tfidf_text)\n",
    "y_pred_cv_text = clf_text.predict(X_cv_tfidf_text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "y_pred_train_title = clf_title.predict(X_train_tfidf_title)\n",
    "y_pred_cv_title = clf_title.predict(X_cv_tfidf_title)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "       c#  javascript  java  python  php  html  jquery  .net  asp.net  \\\n0     0.0         0.0   0.0     0.0  0.0   0.0     0.0   0.0      0.0   \n1     0.0         0.0   0.0     0.0  0.0   0.0     0.0   0.0      0.0   \n2     0.0         0.0   0.0     0.0  0.0   0.0     0.0   0.0      0.0   \n3     0.0         0.0   0.0     0.0  0.0   0.0     0.0   0.0      0.0   \n4     0.0         0.0   1.0     0.0  0.0   0.0     0.0   0.0      0.0   \n...   ...         ...   ...     ...  ...   ...     ...   ...      ...   \n8471  0.0         0.0   0.0     1.0  0.0   0.0     0.0   0.0      0.0   \n8472  0.0         0.0   0.0     1.0  0.0   0.0     0.0   0.0      0.0   \n8473  0.0         0.0   0.0     0.0  0.0   0.0     0.0   0.0      0.0   \n8474  0.0         0.0   0.0     0.0  0.0   0.0     0.0   0.0      0.0   \n8475  0.0         0.0   0.0     0.0  0.0   0.0     0.0   0.0      0.0   \n\n      android  ...  cookies  webpack  dynamic  android-fragments  for-loop  \\\n0         0.0  ...      0.0      0.0      0.0                0.0       0.0   \n1         1.0  ...      0.0      0.0      0.0                0.0       0.0   \n2         0.0  ...      0.0      0.0      0.0                0.0       0.0   \n3         0.0  ...      0.0      0.0      0.0                0.0       0.0   \n4         1.0  ...      0.0      0.0      0.0                0.0       0.0   \n...       ...  ...      ...      ...      ...                ...       ...   \n8471      0.0  ...      0.0      0.0      0.0                0.0       0.0   \n8472      0.0  ...      0.0      0.0      0.0                0.0       0.0   \n8473      0.0  ...      0.0      0.0      0.0                0.0       0.0   \n8474      0.0  ...      0.0      0.0      0.0                0.0       0.0   \n8475      0.0  ...      0.0      0.0      0.0                0.0       0.0   \n\n      sharepoint  codeigniter  pyqt  jsf  windows-phone  \n0            0.0          0.0   0.0  0.0            0.0  \n1            0.0          0.0   0.0  0.0            0.0  \n2            0.0          0.0   0.0  0.0            0.0  \n3            0.0          0.0   0.0  0.0            0.0  \n4            0.0          0.0   0.0  0.0            0.0  \n...          ...          ...   ...  ...            ...  \n8471         0.0          0.0   0.0  0.0            0.0  \n8472         0.0          0.0   0.0  0.0            0.0  \n8473         0.0          0.0   0.0  0.0            0.0  \n8474         0.0          0.0   0.0  0.0            0.0  \n8475         0.0          0.0   0.0  0.0            0.0  \n\n[8476 rows x 231 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>c#</th>\n      <th>javascript</th>\n      <th>java</th>\n      <th>python</th>\n      <th>php</th>\n      <th>html</th>\n      <th>jquery</th>\n      <th>.net</th>\n      <th>asp.net</th>\n      <th>android</th>\n      <th>...</th>\n      <th>cookies</th>\n      <th>webpack</th>\n      <th>dynamic</th>\n      <th>android-fragments</th>\n      <th>for-loop</th>\n      <th>sharepoint</th>\n      <th>codeigniter</th>\n      <th>pyqt</th>\n      <th>jsf</th>\n      <th>windows-phone</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8471</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8472</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8473</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8474</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8475</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>8476 rows Ã— 231 columns</p>\n</div>"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_cv_text_df = pd.DataFrame(y_pred_cv_text)\n",
    "y_pred_cv_text_df.columns = y_cv.columns\n",
    "y_pred_cv_text_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "       c#  javascript  java  python  php  html  jquery  .net  asp.net  \\\n0     0.0         0.0   0.0     0.0  0.0   0.0     0.0   0.0      0.0   \n1     0.0         0.0   0.0     0.0  0.0   0.0     0.0   0.0      0.0   \n2     0.0         0.0   0.0     0.0  0.0   0.0     0.0   0.0      0.0   \n3     0.0         0.0   0.0     0.0  0.0   0.0     0.0   0.0      0.0   \n4     0.0         0.0   1.0     0.0  0.0   0.0     0.0   0.0      0.0   \n...   ...         ...   ...     ...  ...   ...     ...   ...      ...   \n8471  0.0         0.0   0.0     0.0  0.0   0.0     0.0   0.0      0.0   \n8472  0.0         0.0   0.0     1.0  0.0   0.0     0.0   0.0      0.0   \n8473  0.0         0.0   0.0     0.0  0.0   0.0     0.0   0.0      0.0   \n8474  0.0         0.0   0.0     0.0  0.0   0.0     0.0   0.0      0.0   \n8475  0.0         0.0   0.0     0.0  0.0   0.0     0.0   0.0      0.0   \n\n      android  ...  cookies  webpack  dynamic  android-fragments  for-loop  \\\n0         0.0  ...      0.0      0.0      0.0                0.0       0.0   \n1         1.0  ...      0.0      0.0      0.0                0.0       0.0   \n2         0.0  ...      0.0      0.0      0.0                0.0       0.0   \n3         0.0  ...      0.0      0.0      0.0                0.0       0.0   \n4         1.0  ...      0.0      0.0      0.0                0.0       0.0   \n...       ...  ...      ...      ...      ...                ...       ...   \n8471      0.0  ...      0.0      0.0      0.0                0.0       0.0   \n8472      0.0  ...      0.0      0.0      0.0                0.0       0.0   \n8473      0.0  ...      0.0      0.0      0.0                0.0       0.0   \n8474      0.0  ...      0.0      0.0      0.0                0.0       0.0   \n8475      0.0  ...      0.0      0.0      0.0                0.0       0.0   \n\n      sharepoint  codeigniter  pyqt  jsf  windows-phone  \n0            0.0          0.0   0.0  0.0            0.0  \n1            0.0          0.0   0.0  0.0            0.0  \n2            0.0          0.0   0.0  0.0            0.0  \n3            0.0          0.0   0.0  0.0            0.0  \n4            0.0          0.0   0.0  0.0            0.0  \n...          ...          ...   ...  ...            ...  \n8471         0.0          0.0   0.0  0.0            0.0  \n8472         0.0          0.0   0.0  0.0            0.0  \n8473         0.0          0.0   0.0  0.0            0.0  \n8474         0.0          0.0   0.0  0.0            0.0  \n8475         0.0          0.0   0.0  0.0            0.0  \n\n[8476 rows x 231 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>c#</th>\n      <th>javascript</th>\n      <th>java</th>\n      <th>python</th>\n      <th>php</th>\n      <th>html</th>\n      <th>jquery</th>\n      <th>.net</th>\n      <th>asp.net</th>\n      <th>android</th>\n      <th>...</th>\n      <th>cookies</th>\n      <th>webpack</th>\n      <th>dynamic</th>\n      <th>android-fragments</th>\n      <th>for-loop</th>\n      <th>sharepoint</th>\n      <th>codeigniter</th>\n      <th>pyqt</th>\n      <th>jsf</th>\n      <th>windows-phone</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8471</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8472</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8473</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8474</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8475</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>8476 rows Ã— 231 columns</p>\n</div>"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_cv_title_df = pd.DataFrame(y_pred_cv_title)\n",
    "y_pred_cv_title_df.columns = y_cv.columns\n",
    "y_pred_cv_title_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "       c#  javascript  java  python  php  html  jquery  .net  asp.net  \\\n0     1.0         0.0   0.0     0.0  0.0   0.0     0.0   0.0      0.0   \n1     0.0         0.0   0.0     0.0  0.0   0.0     0.0   0.0      0.0   \n2     0.0         0.0   0.0     0.0  0.0   1.0     0.0   0.0      0.0   \n3     0.0         0.0   0.0     0.0  0.0   0.0     0.0   0.0      0.0   \n4     0.0         0.0   1.0     0.0  0.0   0.0     0.0   0.0      0.0   \n...   ...         ...   ...     ...  ...   ...     ...   ...      ...   \n8471  0.0         0.0   0.0     1.0  0.0   0.0     0.0   0.0      0.0   \n8472  0.0         0.0   0.0     2.0  0.0   0.0     0.0   0.0      0.0   \n8473  0.0         0.0   0.0     0.0  0.0   0.0     0.0   0.0      0.0   \n8474  0.0         0.0   0.0     0.0  1.0   1.0     0.0   0.0      0.0   \n8475  0.0         0.0   0.0     0.0  0.0   0.0     0.0   0.0      0.0   \n\n      android  ...  cookies  webpack  dynamic  android-fragments  for-loop  \\\n0         0.0  ...      0.0      0.0      0.0                0.0       0.0   \n1         1.0  ...      0.0      0.0      0.0                0.0       0.0   \n2         0.0  ...      0.0      0.0      0.0                0.0       0.0   \n3         0.0  ...      0.0      0.0      0.0                0.0       0.0   \n4         1.0  ...      0.0      0.0      0.0                1.0       0.0   \n...       ...  ...      ...      ...      ...                ...       ...   \n8471      0.0  ...      0.0      0.0      0.0                0.0       0.0   \n8472      0.0  ...      0.0      0.0      0.0                0.0       0.0   \n8473      1.0  ...      0.0      0.0      0.0                0.0       0.0   \n8474      0.0  ...      0.0      0.0      0.0                0.0       0.0   \n8475      0.0  ...      0.0      0.0      0.0                0.0       0.0   \n\n      sharepoint  codeigniter  pyqt  jsf  windows-phone  \n0            0.0          0.0   0.0  0.0            2.0  \n1            0.0          0.0   0.0  0.0            0.0  \n2            0.0          0.0   0.0  0.0            0.0  \n3            0.0          0.0   0.0  0.0            0.0  \n4            0.0          0.0   0.0  0.0            0.0  \n...          ...          ...   ...  ...            ...  \n8471         0.0          0.0   0.0  0.0            0.0  \n8472         0.0          0.0   0.0  0.0            0.0  \n8473         0.0          0.0   0.0  0.0            0.0  \n8474         0.0          0.0   0.0  0.0            0.0  \n8475         0.0          0.0   0.0  0.0            0.0  \n\n[8476 rows x 231 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>c#</th>\n      <th>javascript</th>\n      <th>java</th>\n      <th>python</th>\n      <th>php</th>\n      <th>html</th>\n      <th>jquery</th>\n      <th>.net</th>\n      <th>asp.net</th>\n      <th>android</th>\n      <th>...</th>\n      <th>cookies</th>\n      <th>webpack</th>\n      <th>dynamic</th>\n      <th>android-fragments</th>\n      <th>for-loop</th>\n      <th>sharepoint</th>\n      <th>codeigniter</th>\n      <th>pyqt</th>\n      <th>jsf</th>\n      <th>windows-phone</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8471</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8472</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8473</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8474</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8475</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>8476 rows Ã— 231 columns</p>\n</div>"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cv = y_cv.reset_index(drop=True)\n",
    "y_cv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#reduire dataset a 10K questions et trier par tags. Justifier pour des questions de resources.\n",
    "# sentence BERT\n",
    "# API choisir la methode - choisir quelle approche (non-supervise ou supervise) cela implique que l'on peut appeler ton algorithme avec une fonction.une fonction qui appelle le modele que je vais choisir.\n",
    "# faire une requette qui envoi une question, la fonction prend en compte la question et renvoi l'output cad la prediction (tags)\n",
    "# le choix est methode avce good accuracy et rapide pour sortir les predictions ( cad inference) - j'ai pris en compte et l'accuracy et l'inference.\n",
    "# un embedding par phrase BERT produit un embedding par mot donc la moyenne rapporte par phrase\n",
    "# sentence_bert permet d'eviter l'etape de moyenne car l'hypothese de la moyenne est correct meme le papier de BERT n'a jamais confirmÃ© cette hypothese.\n",
    "# BERT - entity recognition - reconnaitre des entites en NLP, par ex dans un cadre de contrat avoir un outil qui reconnait les organisations, termes sensibles, juridiques, les personnes etc.. BERT peut etre utilise tel qu'il est pour ce genre d'algo. BERT n'est pas directement fait pour de la classification de texte et sentence bert a ete fine-tunnÃ© pour la classification de texte.\n",
    "# code python - fonction process et transforme en embedding la question,"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#fonction pre-processing\n",
    "# fonction CountVectoriser\n",
    "# fonction qui appelle LDA / load le modele\n",
    "# 1 fonction qui appelle les 3 fonctions\n",
    "# import Flask - 2-3 lignes qui s'ajoute pour creer l'API\n",
    "#https://github.com/jeugregg/Stack-Overflow-tagger/blob/master/tagger_app.py\n",
    "# 2h pour comparer tes differentes approches (LDA, supervises, non-supervises)\n",
    "# faire une demo lors de la soutenance mais pas de question sur l'API en soi lors de la soutenance."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load a pre-trained BERT model and tokenizer\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def sentences_features(sentences):\n",
    "    features = []\n",
    "    # sentences_embeddings = []\n",
    "    for sentence in sentences:\n",
    "        print(\"--------------- New Sentence ------------ \")\n",
    "        tokenized_sentence = bert_tokenizer.encode_plus(sentence,\n",
    "                                                        None,\n",
    "                                                        truncation=True,\n",
    "                                                        add_special_tokens=True,\n",
    "                                                        max_length=512,\n",
    "                                                        padding='max_length',\n",
    "                                                        return_token_type_ids=True,\n",
    "                                                        return_tensors='pt')\n",
    "\n",
    "        bert_output = bert_model(**tokenized_sentence)\n",
    "        # sentences_embeddings.append(bert_output[0][0])\n",
    "        last_hidden_states = bert_output.last_hidden_state.detach()\n",
    "        features_bert = np.array(last_hidden_states).mean(axis=1)\n",
    "        features.append(features_bert)\n",
    "        print(len(features))\n",
    "    print('-----------ALL SENTENCES VECTORIZED ---------')\n",
    "    return features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "feature_bert = sentences_features(sentences)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "feature_bert"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_bert_features = pd.Dataframe(feature_bert)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_bert_features.to_csv('/Users/maurelco/Developer/Python/Projet4/data/Cleaned/df_bert_features.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print (\"Number of layers:\", len(last_hidden_states), \"  (initial embeddings + 12 BERT layers)\")\n",
    "layer_i = 0\n",
    "print (\"Number of batches:\", len(last_hidden_states))\n",
    "batch_i = 0\n",
    "print (\"Number of tokens:\", len(last_hidden_states[layer_i]))\n",
    "token_i = 0\n",
    "print (\"Number of hidden units:\", len(last_hidden_states[layer_i][batch_i]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "last_hidden_states = last_hidden_states.detach()\n",
    "features_bert = np.array(last_hidden_states).mean(axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "last_hidden_states"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Tokenize and convert sentences to BERT input format\n",
    "bert_inputs = []\n",
    "attention_masks = []\n",
    "\n",
    "# Load a pre-trained BERT model and tokenizer\n",
    "\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize and convert sentences to BERT input format\n",
    "for sentence in sentences:\n",
    "    tokenized_sentence = bert_tokenizer.tokenize(sentence)\n",
    "    bert_input = bert_tokenizer.convert_tokens_to_ids(tokenized_sentence)\n",
    "    attention_mask = [1] * len(bert_input)\n",
    "    bert_inputs.append(bert_input)\n",
    "    attention_masks.append(attention_mask)\n",
    "\n",
    "# Convert bert_inputs and attention_masks to Pytorch tensors\n",
    "bert_inputs = torch.tensor(bert_inputs)\n",
    "attention_masks = torch.tensor(attention_masks)\n",
    "\n",
    "# tokenized_sentence = bert_tokenizer.tokenize(df['Text'])\n",
    "# bert_inputs = bert_tokenizer(df_original['Text'], padding=True, return_tensors=\"pt\")\n",
    "# bert_output = bert_model(**bert_inputs)\n",
    "# sentence_embedding = bert_output[0]\n",
    "\n",
    "\n",
    "# Generate sentence embeddings\n",
    "bert_outputs = bert_model(bert_inputs, attention_mask=attention_masks)\n",
    "sentence_embeddings = bert_outputs[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_original['Text_tokens']= df_original['Text'].apply(lambda x : bert_tokenizer.tokenize(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_original['Text_tokens'][1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_original['Text_bert']= df_original['Text_tokens'].apply(lambda x : bert_tokenizer(x, padding=True, return_tensors=\"pt\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(df_original['Text_bert'][1].attention_mask[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_original['Text_bert'][1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_original['Text_bert_model']= df_original['Text_bert'].apply(lambda x : bert_model(input_ids=x['input_ids'], attention_mask=x['attention_mask'], token_type_ids=x['token_type_ids']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bert_model.eval()\n",
    "\n",
    "output_list = []\n",
    "for item in df_original['Text_bert']:\n",
    "    input_ids = item['input_ids'][0].unsqueeze(0)\n",
    "    attention_mask = item['attention_mask'][0].unsqueeze(0)\n",
    "    token_type_ids = item['token_type_ids'][0].unsqueeze(0)\n",
    "    output = bert_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "    output_list.append(output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_original['Text_bert_model'] = [bert_model(input_ids=item['input_ids'], attention_mask=item['attention_mask'], token_type_ids=item['token_type_ids']) for item in df_original['Text_bert']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Concatenate the input_ids, attention_masks, and token_type_ids into a single tensor\n",
    "input_ids = torch.cat([x['input_ids'] for x in df_original['Text_bert']], dim=0)\n",
    "attention_masks = torch.cat([x['attention_mask'] for x in df_original['Text_bert']], dim=0)\n",
    "token_type_ids = torch.cat([x['token_type_ids'] for x in df_original['Text_bert']], dim=0)\n",
    "\n",
    "# Create a TensorDataset from the input_ids, attention_masks, and token_type_ids\n",
    "data = TensorDataset(input_ids, attention_masks, token_type_ids)\n",
    "\n",
    "# Create a DataLoader from the TensorDataset\n",
    "dataloader = DataLoader(data, batch_size=32, shuffle=True)\n",
    "\n",
    "# Iterate over the DataLoader\n",
    "for input_ids, attention_masks, token_type_ids in dataloader:\n",
    "    # Apply the BERT model to the input_ids, attention_masks, and token_type_ids\n",
    "    bert_output = bert_model(input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids)\n",
    "    # Extract the sentence embeddings from the BERT output\n",
    "    sentence_embeddings = bert_output[0]\n",
    "    # Do something with the sentence_embeddings"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bert_inputs = truncate_sequences(bert_inputs, max_length=512, stride=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_original['Text_bert']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(df_original['Text_bert'][1].input_ids[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_original['Text_bert'][1].input_ids[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_original['Text_bert'][1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(len(df_original['Text_bert'])):\n",
    "    print(f'element {i} has shape {df_original[\"Text_bert\"][i][\"input_ids\"].shape}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "same_shape = True\n",
    "first_shape = df_original['Text_bert'][0]['input_ids'].shape\n",
    "for i in range(1, len(df_original['Text_bert'])):\n",
    "    if df_original['Text_bert'][i]['input_ids'].shape != first_shape:\n",
    "        same_shape = False\n",
    "        break\n",
    "if same_shape:\n",
    "    input_ids = torch.cat([x['input_ids'] for x in df_original['Text_bert']], dim=0)\n",
    "    attention_mask = torch.cat([x['attention_mask'] for x in df_original['Text_bert']], dim=0)\n",
    "    token_type_ids = torch.cat([x['token_type_ids'] for x in df_original['Text_bert']], dim=0)\n",
    "else:\n",
    "    print(\"The tensors have different shapes, they can not be concatenated\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_original"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_original.to_csv('/Users/maurelco/Developer/Python/Projet4/data/Cleaned/df_bert.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/maurelco/Developer/Python/Projet4/data/Cleaned/df_bert.csv')\n",
    "df_original.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_original['Text_bert'][0][:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_ids = torch.cat([x['input_ids'] for x in df_original['Text_bert']], dim=0)\n",
    "attention_mask = torch.cat([x['attention_mask'] for x in df_original['Text_bert']], dim=0)\n",
    "token_type_ids = torch.cat([x['token_type_ids'] for x in df_original['Text_bert']], dim=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_original['Text_bert']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Stack the data\n",
    "input_ids = torch.cat([x['input_ids'] for x in df_original['Text_bert']], dim=0)\n",
    "attention_mask = torch.cat([x['attention_mask'] for x in df_original['Text_bert']], dim=0)\n",
    "token_type_ids = torch.cat([x['token_type_ids'] for x in df_original['Text_bert']], dim=0)\n",
    "\n",
    "# Create a TensorDataset\n",
    "data = TensorDataset(input_ids, attention_mask, token_type_ids)\n",
    "\n",
    "# Create a DataLoader\n",
    "dataloader = DataLoader(data, batch_size=32, shuffle=True)\n",
    "\n",
    "# Iterate over the data\n",
    "for batch in dataloader:\n",
    "    input_ids_batch, attention_mask_batch, token_type_ids_batch = batch\n",
    "    output = bert_model(input_ids_batch, attention_mask=attention_mask_batch, token_type_ids=token_type_ids_batch)\n",
    "    # Do something with the output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pandarallel import pandarallel\n",
    "df_original['Text_bert_model']= df_original['Text_bert'].apply(lambda x : bert_model(**x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TypeError: BertModel(\n",
    "#     (embeddings): BertEmbeddings(\n",
    "#     (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
    "# (position_embeddings): Embedding(512, 768)\n",
    "# (token_type_embeddings): Embedding(2, 768)\n",
    "# (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "# (dropout): Dropout(p=0.1, inplace=False)\n",
    "# )\n",
    "# (encoder): BertEncoder(\n",
    "#     (layer): ModuleList(\n",
    "#     (0): BertLayer(\n",
    "#     (attention): BertAttention(\n",
    "#     (self): BertSelfAttention(\n",
    "#     (query): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (key): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (value): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (dropout): Dropout(p=0.1, inplace=False)\n",
    "# )\n",
    "# (output): BertSelfOutput(\n",
    "#     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "# (dropout): Dropout(p=0.1, inplace=False)\n",
    "# )\n",
    "# )\n",
    "# (intermediate): BertIntermediate(\n",
    "#     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
    "# (intermediate_act_fn): GELUActivation()\n",
    "# )\n",
    "# (output): BertOutput(\n",
    "#     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
    "# (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "# (dropout): Dropout(p=0.1, inplace=False)\n",
    "# )\n",
    "# )\n",
    "# (1): BertLayer(\n",
    "#     (attention): BertAttention(\n",
    "#     (self): BertSelfAttention(\n",
    "#     (query): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (key): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (value): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (dropout): Dropout(p=0.1, inplace=False)\n",
    "# )\n",
    "# (output): BertSelfOutput(\n",
    "#     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "# (dropout): Dropout(p=0.1, inplace=False)\n",
    "# )\n",
    "# )\n",
    "# (intermediate): BertIntermediate(\n",
    "#     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
    "# (intermediate_act_fn): GELUActivation()\n",
    "# )\n",
    "# (output): BertOutput(\n",
    "#     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
    "# (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "# (dropout): Dropout(p=0.1, inplace=False)\n",
    "# )\n",
    "# )\n",
    "# (2): BertLayer(\n",
    "#     (attention): BertAttention(\n",
    "#     (self): BertSelfAttention(\n",
    "#     (query): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (key): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (value): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (dropout): Dropout(p=0.1, inplace=False)\n",
    "# )\n",
    "# (output): BertSelfOutput(\n",
    "#     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "# (dropout): Dropout(p=0.1, inplace=False)\n",
    "# )\n",
    "# )\n",
    "# (intermediate): BertIntermediate(\n",
    "#     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
    "# (intermediate_act_fn): GELUActivation()\n",
    "# )\n",
    "# (output): BertOutput(\n",
    "#     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
    "# (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "# (dropout): Dropout(p=0.1, inplace=False)\n",
    "# )\n",
    "# )\n",
    "# (3): BertLayer(\n",
    "#     (attention): BertAttention(\n",
    "#     (self): BertSelfAttention(\n",
    "#     (query): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (key): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (value): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (dropout): Dropout(p=0.1, inplace=False)\n",
    "# )\n",
    "# (output): BertSelfOutput(\n",
    "#     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "# (dropout): Dropout(p=0.1, inplace=False)\n",
    "# )\n",
    "# )\n",
    "# (intermediate): BertIntermediate(\n",
    "#     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
    "# (intermediate_act_fn): GELUActivation()\n",
    "# )\n",
    "# (output): BertOutput(\n",
    "#     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
    "# (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "# (dropout): Dropout(p=0.1, inplace=False)\n",
    "# )\n",
    "# )\n",
    "# (4): BertLayer(\n",
    "#     (attention): BertAttention(\n",
    "#     (self): BertSelfAttention(\n",
    "#     (query): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (key): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (value): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (dropout): Dropout(p=0.1, inplace=False)\n",
    "# )\n",
    "# (output): BertSelfOutput(\n",
    "#     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "# (dropout): Dropout(p=0.1, inplace=False)\n",
    "# )\n",
    "# )\n",
    "# (intermediate): BertIntermediate(\n",
    "#     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
    "# (intermediate_act_fn): GELUActivation()\n",
    "# )\n",
    "# (output): BertOutput(\n",
    "#     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
    "# (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "# (dropout): Dropout(p=0.1, inplace=False)\n",
    "# )\n",
    "# )\n",
    "# (5): BertLayer(\n",
    "#     (attention): BertAttention(\n",
    "#     (self): BertSelfAttention(\n",
    "#     (query): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (key): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (value): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (dropout): Dropout(p=0.1, inplace=False)\n",
    "# )\n",
    "# (output): BertSelfOutput(\n",
    "#     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "# (dropout): Dropout(p=0.1, inplace=False)\n",
    "# )\n",
    "# )\n",
    "# (intermediate): BertIntermediate(\n",
    "#     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
    "# (intermediate_act_fn): GELUActivation()\n",
    "# )\n",
    "# (output): BertOutput(\n",
    "#     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
    "# (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "# (dropout): Dropout(p=0.1, inplace=False)\n",
    "# )\n",
    "# )\n",
    "# (6): BertLayer(\n",
    "#     (attention): BertAttention(\n",
    "#     (self): BertSelfAttention(\n",
    "#     (query): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (key): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (value): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (dropout): Dropout(p=0.1, inplace=False)\n",
    "# )\n",
    "# (output): BertSelfOutput(\n",
    "#     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "# (dropout): Dropout(p=0.1, inplace=False)\n",
    "# )\n",
    "# )\n",
    "# (intermediate): BertIntermediate(\n",
    "#     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
    "# (intermediate_act_fn): GELUActivation()\n",
    "# )\n",
    "# (output): BertOutput(\n",
    "#     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
    "# (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "# (dropout): Dropout(p=0.1, inplace=False)\n",
    "# )\n",
    "# )\n",
    "# (7): BertLayer(\n",
    "#     (attention): BertAttention(\n",
    "#     (self): BertSelfAttention(\n",
    "#     (query): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (key): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (value): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (dropout): Dropout(p=0.1, inplace=False)\n",
    "# )\n",
    "# (output): BertSelfOutput(\n",
    "#     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "# (dropout): Dropout(p=0.1, inplace=False)\n",
    "# )\n",
    "# )\n",
    "# (intermediate): BertIntermediate(\n",
    "#     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
    "# (intermediate_act_fn): GELUActivation()\n",
    "# )\n",
    "# (output): BertOutput(\n",
    "#     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
    "# (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "# (dropout): Dropout(p=0.1, inplace=False)\n",
    "# )\n",
    "# )\n",
    "# (8): BertLayer(\n",
    "#     (attention): BertAttention(\n",
    "#     (self): BertSelfAttention(\n",
    "#     (query): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (key): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (value): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (dropout): Dropout(p=0.1, inplace=False)\n",
    "# )\n",
    "# (output): BertSelfOutput(\n",
    "#     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "# (dropout): Dropout(p=0.1, inplace=False)\n",
    "# )\n",
    "# )\n",
    "# (intermediate): BertIntermediate(\n",
    "#     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
    "# (intermediate_act_fn): GELUActivation()\n",
    "# )\n",
    "# (output): BertOutput(\n",
    "#     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
    "# (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "# (dropout): Dropout(p=0.1, inplace=False)\n",
    "# )\n",
    "# )\n",
    "# (9): BertLayer(\n",
    "#     (attention): BertAttention(\n",
    "#     (self): BertSelfAttention(\n",
    "#     (query): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (key): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (value): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (dropout): Dropout(p=0.1, inplace=False)\n",
    "# )\n",
    "# (output): BertSelfOutput(\n",
    "#     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "# (dropout): Dropout(p=0.1, inplace=False)\n",
    "# )\n",
    "# )\n",
    "# (intermediate): BertIntermediate(\n",
    "#     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
    "# (intermediate_act_fn): GELUActivation()\n",
    "# )\n",
    "# (output): BertOutput(\n",
    "#     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
    "# (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "# (dropout): Dropout(p=0.1, inplace=False)\n",
    "# )\n",
    "# )\n",
    "# (10): BertLayer(\n",
    "#     (attention): BertAttention(\n",
    "#     (self): BertSelfAttention(\n",
    "#     (query): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (key): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (value): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (dropout): Dropout(p=0.1, inplace=False)\n",
    "# )\n",
    "# (output): BertSelfOutput(\n",
    "#     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "# (dropout): Dropout(p=0.1, inplace=False)\n",
    "# )\n",
    "# )\n",
    "# (intermediate): BertIntermediate(\n",
    "#     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
    "# (intermediate_act_fn): GELUActivation()\n",
    "# )\n",
    "# (output): BertOutput(\n",
    "#     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
    "# (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "# (dropout): Dropout(p=0.1, inplace=False)\n",
    "# )\n",
    "# )\n",
    "# (11): BertLayer(\n",
    "#     (attention): BertAttention(\n",
    "#     (self): BertSelfAttention(\n",
    "#     (query): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (key): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (value): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (dropout): Dropout(p=0.1, inplace=False)\n",
    "# )\n",
    "# (output): BertSelfOutput(\n",
    "#     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "# (dropout): Dropout(p=0.1, inplace=False)\n",
    "# )\n",
    "# )\n",
    "# (intermediate): BertIntermediate(\n",
    "#     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
    "# (intermediate_act_fn): GELUActivation()\n",
    "# )\n",
    "# (output): BertOutput(\n",
    "#     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
    "# (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "# (dropout): Dropout(p=0.1, inplace=False)\n",
    "# )\n",
    "# )\n",
    "# )\n",
    "# )\n",
    "# (pooler): BertPooler(\n",
    "#     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
    "# (activation): Tanh()\n",
    "# )\n",
    "# ) argument after ** must be a mapping, not str\n",
    "#\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test = df_original['Text'][0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_original"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input = bert_tokenizer(test, padding=True, return_tensors=\"pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(input['input_ids'][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bert_output = bert_model(**bert_inputs)\n",
    "sentence_embedding = bert_output[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# etre capable de trouver un embedding qui est representatif du mot dans son context\n",
    "# BERT est BasÃ© sur des Transformers\n",
    "# les Transformers utisent des mecanismes d'attention (Ã  regarder) - c'est ca qui donne la puissance de ces methode et generer un embedding qui depend du context."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bert_output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#for loop on each sentence to mean and exctract features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#sentence_bert - model basÃ© sur BERT (modele jumeaux) entrainer pour retourner pour chaque phrase l'embedding qui correspond, un embedding representatif de la phrase par rapport au text), retourne un embedding par phrase. Est-ce dispo dans Transformers? chercher a aller plus loin, plutot que faire la moyenne.\n",
    "# ajoute une appriche en plus"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#creer un compte avec google colab -"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bert_large_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Save the model\n",
    "torch.save(bert_model.state_dict(), 'bert_model.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the model\n",
    "loaded_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "loaded_model.load_state_dict(torch.load('bert_model.pt'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(bert_tokenizer.state_dict(), 'bert_tokenizer.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loaded_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "loaded_tokenizer.load_state_dict(torch.load('bert_tokenizer.pt'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bert_outputs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sentence_embeddings"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## BERT SENTENCES - autre approche"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}