{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize,wordpunct_tokenize\n",
    "from nltk.corpus import words\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 6 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "pandarallel.initialize(progress_bar=True,\n",
    "                        nb_workers=6,\n",
    "                        #verbose=1\n",
    "                       )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/maurelco/Developer/Python/Projet 4/data/Source/QueryResults-3.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/maurelco/Developer/Python/Projet 4/data/cleaned/df_cleaned.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   Title  \\\n0      Giving a unix process exclusive RW access to a...   \n1               automatic repaint when minimizing window   \n2      Is man-in-the-middle attack a security threat ...   \n3          Managing data access in a simple WinForms app   \n4                                Render basic HTML view?   \n...                                                  ...   \n49995  Bypass Vertica ERROR 3326: Execution time exce...   \n49996  A conflicting conditional operation is current...   \n49997      Problem in lr_find() in Pytorch fastai course   \n49998     JSONPatch escape slash '/' from JSONPatch+JSON   \n49999  org.gradle.internal.resolve.ArtifactNotFoundEx...   \n\n                                                    Body  \\\n0      is there a way to sandbox a linux process into...   \n1      i have a jframe, with two panels, in one panel...   \n2      i am no expert in network security, so pardon ...   \n3      i have a simple winforms data entry app that u...   \n4      i have a basic node.js app that i am trying to...   \n...                                                  ...   \n49995  using the ssis tool and ole db, we are downloa...   \n49996  using s3fs, i am uploading a file to the alrea...   \n49997  while following the jupyter notebooks for the ...   \n49998  i've below json and i wanted to update few fie...   \n49999  i am using 15.0.1 version of firebase and goog...   \n\n                                                    Tags  \n0             <linux><ubuntu><process><sandbox><selinux>  \n1                <java><graphics><jframe><jpanel><paint>  \n2      <security><ssh><ssh-keys><openssh><man-in-the-...  \n3       <c#><winforms><sqlite><datatable><sqlconnection>  \n4          <javascript><html><node.js><mongodb><express>  \n...                                                  ...  \n49995  <sql-server><ssas><oledb><sql-server-data-tool...  \n49996  <python><amazon-web-services><amazon-s3><boto3...  \n49997  <python><machine-learning><deep-learning><pyto...  \n49998         <java><json><rest><json-patch><http-patch>  \n49999  <android><android-studio><android-gradle-plugi...  \n\n[50000 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Title</th>\n      <th>Body</th>\n      <th>Tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Giving a unix process exclusive RW access to a...</td>\n      <td>is there a way to sandbox a linux process into...</td>\n      <td>&lt;linux&gt;&lt;ubuntu&gt;&lt;process&gt;&lt;sandbox&gt;&lt;selinux&gt;</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>automatic repaint when minimizing window</td>\n      <td>i have a jframe, with two panels, in one panel...</td>\n      <td>&lt;java&gt;&lt;graphics&gt;&lt;jframe&gt;&lt;jpanel&gt;&lt;paint&gt;</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Is man-in-the-middle attack a security threat ...</td>\n      <td>i am no expert in network security, so pardon ...</td>\n      <td>&lt;security&gt;&lt;ssh&gt;&lt;ssh-keys&gt;&lt;openssh&gt;&lt;man-in-the-...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Managing data access in a simple WinForms app</td>\n      <td>i have a simple winforms data entry app that u...</td>\n      <td>&lt;c#&gt;&lt;winforms&gt;&lt;sqlite&gt;&lt;datatable&gt;&lt;sqlconnection&gt;</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Render basic HTML view?</td>\n      <td>i have a basic node.js app that i am trying to...</td>\n      <td>&lt;javascript&gt;&lt;html&gt;&lt;node.js&gt;&lt;mongodb&gt;&lt;express&gt;</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49995</th>\n      <td>Bypass Vertica ERROR 3326: Execution time exce...</td>\n      <td>using the ssis tool and ole db, we are downloa...</td>\n      <td>&lt;sql-server&gt;&lt;ssas&gt;&lt;oledb&gt;&lt;sql-server-data-tool...</td>\n    </tr>\n    <tr>\n      <th>49996</th>\n      <td>A conflicting conditional operation is current...</td>\n      <td>using s3fs, i am uploading a file to the alrea...</td>\n      <td>&lt;python&gt;&lt;amazon-web-services&gt;&lt;amazon-s3&gt;&lt;boto3...</td>\n    </tr>\n    <tr>\n      <th>49997</th>\n      <td>Problem in lr_find() in Pytorch fastai course</td>\n      <td>while following the jupyter notebooks for the ...</td>\n      <td>&lt;python&gt;&lt;machine-learning&gt;&lt;deep-learning&gt;&lt;pyto...</td>\n    </tr>\n    <tr>\n      <th>49998</th>\n      <td>JSONPatch escape slash '/' from JSONPatch+JSON</td>\n      <td>i've below json and i wanted to update few fie...</td>\n      <td>&lt;java&gt;&lt;json&gt;&lt;rest&gt;&lt;json-patch&gt;&lt;http-patch&gt;</td>\n    </tr>\n    <tr>\n      <th>49999</th>\n      <td>org.gradle.internal.resolve.ArtifactNotFoundEx...</td>\n      <td>i am using 15.0.1 version of firebase and goog...</td>\n      <td>&lt;android&gt;&lt;android-studio&gt;&lt;android-gradle-plugi...</td>\n    </tr>\n  </tbody>\n</table>\n<p>50000 rows Ã— 3 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Data cleaning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.1 NaN values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.nunique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.isna().mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.heatmap(df.isna())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.2 Duplicated values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.duplicated(subset='Body').sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.3 Selection of important features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tmp= df.dtypes\n",
    "tmp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cols = ['Title','Body','Tags']\n",
    "df = df[cols]\n",
    "df.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.4 Delete HTML and Lower text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['Body']= df['Body'].apply(lambda x: (BeautifulSoup(x).get_text()).lower())\n",
    "df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "                                               Title  \\\n0  giving a unix process exclusive rw access to a...   \n1           automatic repaint when minimizing window   \n2  is man-in-the-middle attack a security threat ...   \n3      managing data access in a simple winforms app   \n4                            render basic html view?   \n5  how to use nested-subfloders routing in nodejs...   \n6  using generics to process asp.net form request...   \n7  simple select(*) queries very slow in apache i...   \n8  ms sql server optimizer and varying table and ...   \n9                     how to wait for process child?   \n\n                                                Body  \\\n0  is there a way to sandbox a linux process into...   \n1  i have a jframe, with two panels, in one panel...   \n2  i am no expert in network security, so pardon ...   \n3  i have a simple winforms data entry app that u...   \n4  i have a basic node.js app that i am trying to...   \n5  i am working on a node project using express. ...   \n6  using jquery to post values back to an asp.net...   \n7  i'm prototyping apache ignite for use in a new...   \n8  we have a lot of queries for which we append a...   \n9  i do the usual fork + exec combination:\\nint s...   \n\n                                                Tags  \n0         <linux><ubuntu><process><sandbox><selinux>  \n1            <java><graphics><jframe><jpanel><paint>  \n2  <security><ssh><ssh-keys><openssh><man-in-the-...  \n3   <c#><winforms><sqlite><datatable><sqlconnection>  \n4      <javascript><html><node.js><mongodb><express>  \n5  <node.js><express><routes><nested-routes><modu...  \n6      <c#><asp.net><generics><reflection><webforms>  \n7  <sql><performance><key-value><ignite><in-memor...  \n8  <sql><sql-server><sql-server-2005><tsql><query...  \n9                   <linux><posix><exec><fork><wait>  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Title</th>\n      <th>Body</th>\n      <th>Tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>giving a unix process exclusive rw access to a...</td>\n      <td>is there a way to sandbox a linux process into...</td>\n      <td>&lt;linux&gt;&lt;ubuntu&gt;&lt;process&gt;&lt;sandbox&gt;&lt;selinux&gt;</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>automatic repaint when minimizing window</td>\n      <td>i have a jframe, with two panels, in one panel...</td>\n      <td>&lt;java&gt;&lt;graphics&gt;&lt;jframe&gt;&lt;jpanel&gt;&lt;paint&gt;</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>is man-in-the-middle attack a security threat ...</td>\n      <td>i am no expert in network security, so pardon ...</td>\n      <td>&lt;security&gt;&lt;ssh&gt;&lt;ssh-keys&gt;&lt;openssh&gt;&lt;man-in-the-...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>managing data access in a simple winforms app</td>\n      <td>i have a simple winforms data entry app that u...</td>\n      <td>&lt;c#&gt;&lt;winforms&gt;&lt;sqlite&gt;&lt;datatable&gt;&lt;sqlconnection&gt;</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>render basic html view?</td>\n      <td>i have a basic node.js app that i am trying to...</td>\n      <td>&lt;javascript&gt;&lt;html&gt;&lt;node.js&gt;&lt;mongodb&gt;&lt;express&gt;</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>how to use nested-subfloders routing in nodejs...</td>\n      <td>i am working on a node project using express. ...</td>\n      <td>&lt;node.js&gt;&lt;express&gt;&lt;routes&gt;&lt;nested-routes&gt;&lt;modu...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>using generics to process asp.net form request...</td>\n      <td>using jquery to post values back to an asp.net...</td>\n      <td>&lt;c#&gt;&lt;asp.net&gt;&lt;generics&gt;&lt;reflection&gt;&lt;webforms&gt;</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>simple select(*) queries very slow in apache i...</td>\n      <td>i'm prototyping apache ignite for use in a new...</td>\n      <td>&lt;sql&gt;&lt;performance&gt;&lt;key-value&gt;&lt;ignite&gt;&lt;in-memor...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>ms sql server optimizer and varying table and ...</td>\n      <td>we have a lot of queries for which we append a...</td>\n      <td>&lt;sql&gt;&lt;sql-server&gt;&lt;sql-server-2005&gt;&lt;tsql&gt;&lt;query...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>how to wait for process child?</td>\n      <td>i do the usual fork + exec combination:\\nint s...</td>\n      <td>&lt;linux&gt;&lt;posix&gt;&lt;exec&gt;&lt;fork&gt;&lt;wait&gt;</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Title']= df['Title'].apply(lambda x: x.lower())\n",
    "df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "\"why 0/0 is nan but 0/0.00 isn't\""
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Title'][37847]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### ... Saving the cleaned dataset ..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "df.to_csv(\"data/cleaned/df_cleaned.csv\", index= False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### ... cleaned dataset saved ..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.4 Analysis of the words frequency"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.describe(include=np.number)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.describe(include=object)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.Tags.value_counts()[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tmp = df.Body.str.len()\n",
    "sns.displot(tmp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.boxplot(tmp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"_len_txt\"] = tmp\n",
    "df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.sort_values('_len_txt').head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.sort_values('_len_txt').tail(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.drop(columns='_len_txt',inplace=True)\n",
    "df.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2 Preliminary text processing analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.1 Tokenization selection"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def display_tokens_info(tokens):\n",
    "    \"\"\"display info about corpus\"\"\"\n",
    "    print(f\"nb tokens {len(tokens)}, nb tokens uniques {len(set(tokens))}\")\n",
    "    print(tokens[:1000])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "doc = df.Body.sample(1)\n",
    "doc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "doc = doc.values[0]\n",
    "doc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "txt_1 = f\"tag : {df['Tags'][27287]}\\n\"\n",
    "txt_2 = f\"title : {df['Title'][27287]}\\n\"\n",
    "print(txt_1+txt_2+df['Body'][27287]+\"...\"+\"\\n\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokens_1 = word_tokenize(doc)\n",
    "display_tokens_info(tokens_1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokens_2 = wordpunct_tokenize(doc)\n",
    "display_tokens_info(tokens_2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stop_words = set(nltk.corpus.stopwords.words('English'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokens_1 = [ w for w in tokens_1 if w not in stop_words]\n",
    "display_tokens_info(tokens_1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokens_2 = [ w for w in tokens_2 if w not in stop_words]\n",
    "display_tokens_info(tokens_2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "tokens_3 = tokenizer.tokenize(doc)\n",
    "display_tokens_info(tokens_3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokens_3 = [ w for w in tokens_3 if w not in stop_words]\n",
    "display_tokens_info(tokens_3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.6 1st text processing function / test ..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def process_text(doc,\n",
    "                 rejoin=False):\n",
    "\n",
    "    #tokenizer\n",
    "    tokenizer = nltk.RegexpTokenizer(r'\\w+')\n",
    "    raw_tokens_list = tokenizer.tokenize(doc)\n",
    "\n",
    "    # stop words:\n",
    "    cleaned_tokens_list = [word for word in raw_tokens_list if word not in stop_words]\n",
    "\n",
    "    if rejoin:\n",
    "        return \" \".join(cleaned_tokens_list)\n",
    "\n",
    "    return cleaned_tokens_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokens_4 = process_text(doc)\n",
    "display_tokens_info(tokens_4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.3 Generalization of preliminary text processing to full corpus of answers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "raw_corpus = \"\".join(df.Body.values)\n",
    "raw_corpus[:1000]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corpus = process_text(raw_corpus, rejoin=False)\n",
    "display_tokens_info(corpus)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.4 Preliminary Analysis of Frequency"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tmp = pd.Series(corpus).value_counts()\n",
    "tmp[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tmp.tail(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.boxplot(tmp[tmp < 50])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list_unique_words = list((tmp[tmp == 1]).index)\n",
    "len(list_unique_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### ... saving the words appearing only once in the corpus ..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list_unique_words_df = pd.DataFrame({\"words\" : list_unique_words})\n",
    "list_unique_words_df.to_csv(\"data/cleaned/unique_words.csv\", index=False)\n",
    "list_unique_words_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list_min_5_words = list((tmp[tmp < 5]).index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(list_min_5_words )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list_min_5_words.sample(20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### ... saving the words apperaing 5 times or less in the corpus ..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list_min_5_words_df = pd.DataFrame({\"words\" : list_min_5_words})\n",
    "list_min_5_words_df.to_csv(\"data/cleaned/min_5_words.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list_min_10_words = list((tmp[tmp < 10]).index)\n",
    "len(list_min_10_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### ... saving the words appearing 10 times or less in the corpus ..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list_min_10_words_df = pd.DataFrame({\"words\" : list_min_10_words})\n",
    "list_min_10_words_df.to_csv(\"data/cleaned/min_10_words.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def process_text_2(doc,\n",
    "                 rejoin=False,\n",
    "                   list_rare_words = None,\n",
    "                   min_len_word = 2,\n",
    "                   force_is_alpha= False):\n",
    "    #list_unique_words\n",
    "    if not list_rare_words:\n",
    "        list_rare_words = []\n",
    "\n",
    "    #tokenizer\n",
    "    tokenizer = nltk.RegexpTokenizer(r'\\w+')\n",
    "    raw_tokens_list = tokenizer.tokenize(doc)\n",
    "\n",
    "    # stop words:\n",
    "    cleaned_tokens_list = [word for word in raw_tokens_list if word not in stop_words]\n",
    "\n",
    "    #non_rare_tokens\n",
    "    non_rare_tokens = [w for w in cleaned_tokens_list if w not in list_rare_words]\n",
    "\n",
    "    # no more than len\n",
    "    more_than_N = [w for w in non_rare_tokens if len(w) >= min_len_word]\n",
    "\n",
    "    #only alpha characters\n",
    "    if force_is_alpha:\n",
    "        alpha_tokens = [w for w in more_than_N if w.isalpha()]\n",
    "    else:\n",
    "        alpha_tokens = more_than_N\n",
    "\n",
    "    ################################################################################\n",
    "\n",
    "    if rejoin:\n",
    "        return \" \".join(alpha_tokens)\n",
    "\n",
    "    return alpha_tokens"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display_tokens_info(corpus)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(set(corpus))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corpus = process_text_2(raw_corpus, list_rare_words=list_unique_words,rejoin=False)\n",
    "display_tokens_info(corpus)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokens_3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trans_stemmer = nltk.PorterStemmer()\n",
    "trans_text_stemmer = [trans_stemmer.stem(i) for i in tokens_3]\n",
    "print(trans_text_stemmer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(trans_text_stemmer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(set(trans_text_stemmer))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trans_lemma = nltk.PorterStemmer()\n",
    "trans_text_lemma = [trans_lemma.stem(i) for i in tokens_3]\n",
    "print(trans_text_lemma)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(trans_text_lemma)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(set(trans_text_lemma))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def process_text_3(doc,\n",
    "                    rejoin=False,\n",
    "                    list_rare_words = None,\n",
    "                    min_len_word = 2,\n",
    "                    force_is_alpha= True,\n",
    "                    lemm_or_stem = 'lem'):\n",
    "    #list_unique_words\n",
    "    if not list_rare_words:\n",
    "        list_rare_words = []\n",
    "\n",
    "    #tokenizer\n",
    "    tokenizer = nltk.RegexpTokenizer(r'\\w+')\n",
    "    raw_tokens_list = tokenizer.tokenize(doc)\n",
    "    print(raw_tokens_list[:1])\n",
    "\n",
    "    # stop words:\n",
    "    cleaned_tokens_list = [word for word in raw_tokens_list if word not in stop_words]\n",
    "    print(cleaned_tokens_list[:1])\n",
    "\n",
    "    #non_rare_tokens\n",
    "    non_rare_tokens = [w for w in cleaned_tokens_list if w not in list_rare_words]\n",
    "    print(non_rare_tokens[:1])\n",
    "\n",
    "    # no more than len\n",
    "    more_than_N = [w for w in non_rare_tokens if len(w) >= min_len_word]\n",
    "    print(more_than_N[:1])\n",
    "    #only alpha characters\n",
    "    if force_is_alpha:\n",
    "        alpha_tokens = [w for w in more_than_N if w.isalpha()]\n",
    "        print(alpha_tokens[:1])\n",
    "    else:\n",
    "        alpha_tokens = more_than_N\n",
    "\n",
    "    if lemm_or_stem == 'lem' :\n",
    "        trans= WordNetLemmatizer()\n",
    "        trans_text = [trans.lemmatize(i) for i in alpha_tokens]\n",
    "        print(trans_text[:1])\n",
    "    else:\n",
    "        trans = nltk.PorterStemmer()\n",
    "        trans_text = [trans.stem(i) for i in alpha_tokens]\n",
    "\n",
    "    ################################################################################\n",
    "\n",
    "    if rejoin:\n",
    "        return \" \".join(trans_text)\n",
    "\n",
    "    return trans_text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def final_clean(doc):\n",
    "    new_doc = process_text_3(doc,\n",
    "                           rejoin=False,\n",
    "                           list_rare_words=list_unique_words,\n",
    "                           min_len_word=2,\n",
    "                           force_is_alpha=True,\n",
    "                           )\n",
    "    return new_doc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['_clean_text']= df['Body'].parallel_apply(lambda x : final_clean(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corpus = process_text_3(corpus, list_rare_words=list_unique_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display_tokens_info(corpus)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}